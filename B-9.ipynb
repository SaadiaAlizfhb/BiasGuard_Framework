{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a22ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, KBinsDiscretizer, Normalizer, MaxAbsScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.decomposition import PCA, NMF, SparsePCA, KernelPCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, VarianceThreshold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "# !pip install scikit-learn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_S = SVC(kernel='rbf', C=1.0, gamma='scale', verbose=False)\n",
    "classifier_R = RandomForestClassifier(verbose=False)\n",
    "classifier_D = DecisionTreeClassifier()\n",
    "classifier_G = GradientBoostingClassifier(verbose=False)\n",
    "classifier_K = KNeighborsClassifier()\n",
    "classifier_GNB = GaussianNB()\n",
    "classifier_GB = GradientBoostingClassifier(verbose=False)\n",
    "classifier_NN = MLPClassifier()\n",
    "classifier_IDA = QuadraticDiscriminantAnalysis()\n",
    "classifier_QDA = QuadraticDiscriminantAnalysis()\n",
    "classifier_ADB = AdaBoostClassifier()\n",
    "classifier_GP = GaussianProcessClassifier()\n",
    "classifier_XGBC = XGBClassifier(verbosity=0)\n",
    "classifier_LGBM = LGBMClassifier()\n",
    "classifier_BC = BaggingClassifier(verbose=False)\n",
    "classifier_CB = CatBoostClassifier(iterations=100, verbose=False)\n",
    "\n",
    "classifiers = [\n",
    "     ('SVC', classifier_S),\n",
    "     ('RF', classifier_R),\n",
    "     ('DT', classifier_D),\n",
    "       ('GB', classifier_G),\n",
    "     ('KNN', classifier_K),\n",
    "       ('GNB', classifier_GNB),\n",
    "     ('GBC', classifier_GB),\n",
    "     ('NN', classifier_NN),\n",
    "     ('IDA', classifier_IDA),\n",
    "     ('QDA', classifier_QDA),  \n",
    "      ('ADB', classifier_ADB),\n",
    "#      ('GP', classifier_GP),\n",
    "     ('XGB', classifier_XGBC),\n",
    "     ('LGB', classifier_LGBM),\n",
    "     ('BC', classifier_BC),\n",
    "     ('CB', classifier_CB),     \n",
    "]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eac6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Fairness_Metrics_Computation(y1, y2, y, attribute):\n",
    "    # Convert inputs to pandas Series for easier handling\n",
    "    y1 = pd.Series(y1)\n",
    "    y2 = pd.Series(y2)\n",
    "    y = pd.Series(y)\n",
    "    attribute = pd.Series(attribute)\n",
    "\n",
    "    # Identify privileged and unprivileged groups\n",
    "    privileged = (attribute == 'male') | (attribute == 1)\n",
    "    unprivileged = ~privileged\n",
    "\n",
    "    # Counts of privileged and unprivileged groups\n",
    "    count_privileged = np.sum(privileged)\n",
    "    count_unprivileged = np.sum(unprivileged)\n",
    "\n",
    "    # SPD Calculation\n",
    "    SFC_SPD_P = np.sum([(1 if y1_i == 1 and y2_i == 0 else -1 if y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y1_i, y2_i, attr in zip(y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_SPD_NP = np.sum([(1 if y1_i == 1 and y2_i == 0 else -1 if y1_i == 0 and y2_i == 1 else 0)\n",
    "                         for y1_i, y2_i, attr in zip(y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    SFR_SPD_p = SFC_SPD_P / count_privileged if count_privileged > 0 else 0\n",
    "    SFR_SPD_np = SFC_SPD_NP / count_unprivileged if count_unprivileged > 0 else 0\n",
    "    SPD = SFR_SPD_np - SFR_SPD_p\n",
    "\n",
    "    # EOD Calculation\n",
    "    SFC_EOD_P = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_EOD_NP = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                         for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    P_Y1 = np.sum((y == 1) & privileged)\n",
    "    NP_Y1 = np.sum((y == 1) & unprivileged)\n",
    "\n",
    "    SFR_EOD_p = SFC_EOD_P / P_Y1 if P_Y1 > 0 else 0\n",
    "    SFR_EOD_np = SFC_EOD_NP / NP_Y1 if NP_Y1 > 0 else 0\n",
    "    EOD = SFR_EOD_np - SFR_EOD_p\n",
    "\n",
    "    # AOD Calculation\n",
    "    SFC_TP_P = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_TP_NP = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "    SFC_FP_P = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_FP_NP = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    P_Y0 = np.sum((y == 0) & privileged)\n",
    "    NP_Y0 = np.sum((y == 0) & unprivileged)\n",
    "\n",
    "    SFR_AOD_p = (SFC_TP_P / P_Y1 if P_Y1 > 0 else 0) + (SFC_FP_P / P_Y0 if P_Y0 > 0 else 0)\n",
    "    SFR_AOD_np = (SFC_TP_NP / NP_Y1 if NP_Y1 > 0 else 0) + (SFC_FP_NP / NP_Y0 if NP_Y0 > 0 else 0)\n",
    "    AOD = (SFR_AOD_np - SFR_AOD_p) / 2\n",
    "\n",
    "    # ERD Calculation\n",
    "    SFC_FN_P = np.sum([(-1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_FN_NP = np.sum([(-1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "    SFC_FP_P = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_FP_NP = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    SFR_ERR_p = (SFC_FP_P / P_Y0 if P_Y0 > 0 else 0) + (SFC_FN_P / P_Y1 if P_Y1 > 0 else 0)\n",
    "    SFR_ERR_np = (SFC_FP_NP / NP_Y0 if NP_Y0 > 0 else 0) + (SFC_FN_NP / NP_Y1 if NP_Y1 > 0 else 0)\n",
    "    ERD = SFR_ERR_np - SFR_ERR_p\n",
    "\n",
    "    return SPD, EOD, AOD, ERD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59403abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/Saadia/FairPreprocessing/data/bank/bank-additional-full.csv'\n",
    "na_values = ['unknown', 'nan', '']\n",
    "df = pd.read_csv(file_path, sep=';', na_values=na_values)\n",
    "\n",
    "# Apply custom transformations\n",
    "df['age'] = df['age'].apply(lambda x: float(x >= 25))\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define preprocessor for both numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "standard_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define RobustScaler preprocessor for Pipeline 4\n",
    "robust_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define Feature Selection (FS)\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# Define the pipelines with adjusted classifier parameters\n",
    "pipeline_p1 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=10, max_features='sqrt', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p2 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p3 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(min_samples_leaf=6, min_impurity_decrease=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p4 = Pipeline([\n",
    "    ('preprocessor', robust_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_leaf_nodes=16, random_state=42))\n",
    "])\n",
    "\n",
    "# Splitting data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Fit the pipelines on the training data and make predictions\n",
    "pipelines = [pipeline_p1, pipeline_p2, pipeline_p3, pipeline_p4]\n",
    "pipeline_names = ['P1: FS, Stratification, Scaling, DT', 'P2: Stratification, Scaling, DT', 'P3: FS, Scaling, DT', 'P4: FS, Stratification, DT']\n",
    "results = {}\n",
    "\n",
    "y_pred_1 = pipeline_p1.fit(X_train, y_train).predict(X_test)\n",
    "y_pred_2 = pipeline_p2.fit(X_train, y_train).predict(X_test)\n",
    "y_pred_3 = pipeline_p3.fit(X_train, y_train).predict(X_test)\n",
    "y_pred_4 = pipeline_p4.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "results['P1'] = accuracy_score(y_test, y_pred_1)\n",
    "results['P2'] = accuracy_score(y_test, y_pred_2)\n",
    "results['P3'] = accuracy_score(y_test, y_pred_3)\n",
    "results['P4'] = accuracy_score(y_test, y_pred_4)\n",
    "\n",
    "results  # Display the accuracy of each pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = accuracy_score(y_test, y_pred_1)\n",
    "A2 = accuracy_score(y_test,y_pred_2)\n",
    "A3 = accuracy_score(y_test, y_pred_3)\n",
    "A4 = accuracy_score(y_test,y_pred_4)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_1)\n",
    "f2 = f1_score(y_test, y_pred_2)\n",
    "f3 = f1_score(y_test, y_pred_3)\n",
    "f4 = f1_score(y_test, y_pred_4)\n",
    "A1,A2,A3,A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "pipeline_baseline = DummyClassifier(strategy='most_frequent')\n",
    "pipeline_baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = pipeline_baseline.predict(X_test)\n",
    "mispred_baseline = (y_test != y_pred_baseline).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74201249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=X['age'])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "def calculate_biases(mispred_p1, mispred_p2, mispred_p3,mispred_p4, mispred_baseline):\n",
    "    \"\"\"\n",
    "    Calculate individual biases and total bias.\n",
    "\n",
    "    Parameters:\n",
    "    mispred_p1 (int): Mispredictions for P1 (LE+SS+Classifier)\n",
    "    mispred_p2 (int): Mispredictions for P2 (SS+Classifier)\n",
    "    mispred_p3 (int): Mispredictions for P3 (LE+Classifier)\n",
    "    mispred_baseline (int): Mispredictions for the baseline model\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the individual biases and total bias\n",
    "    \"\"\"\n",
    "    # Calculating individual biases\n",
    "    BD = mispred_baseline\n",
    "    BLE = mispred_p1 - mispred_p2\n",
    "    LE_SS_Interaction = mispred_p1 - (mispred_p2 + mispred_p3 - mispred_baseline)\n",
    "\n",
    "    BSS = mispred_p1 - mispred_p3\n",
    "    SS_PC_Interaction = mispred_p1 - (mispred_p2 + mispred_p4 - mispred_baseline)\n",
    "    \n",
    "    BPC = mispred_p1 - mispred_p4\n",
    "    PC_Classifier_Interaction = mispred_p1 - (mispred_p3 + mispred_p4 - mispred_baseline)\n",
    "\n",
    "    # Calculate BC to ensure TB equals mispred_p1\n",
    "    BC = mispred_p1 - (BD + BLE + BSS + BPC + LE_SS_Interaction + SS_PC_Interaction + PC_Classifier_Interaction)\n",
    "\n",
    "    # Calculate the total bias\n",
    "    TB = BD + BLE + BSS + BPC + BC + LE_SS_Interaction + SS_PC_Interaction + PC_Classifier_Interaction\n",
    "\n",
    "    # Returning the results as a dictionary\n",
    "    return {\n",
    "        'BD': BD,\n",
    "\n",
    "        'BSt-1': BLE,\n",
    "        'St1-St2_Interaction': LE_SS_Interaction,\n",
    "        'BSt-2': BSS,\n",
    "        'St2-St3_Interaction': SS_PC_Interaction,\n",
    "        'BSt-3': BPC,\n",
    "              \n",
    "        'St3_Classifier_Interaction': PC_Classifier_Interaction,\n",
    "        'BC': BC,\n",
    "        'TB': TB\n",
    "    }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_biases(biases, mispred_p1):\n",
    "    \"\"\"\n",
    "    Plot biases and observed mispredictions.\n",
    "    \"\"\"\n",
    "    labels = [\n",
    "        'Data (BD)', \n",
    "        \n",
    "        'Preprocessing Stage 1', \n",
    "        'Stage 1-2 Interaction',\n",
    "        'Preprocessing Stage 2', \n",
    "         \n",
    "       \n",
    "        'Stage 2-3 Interaction',\n",
    "        'Preprocessing Stage 3',\n",
    "        'Stage 3-Classifier Interaction',\n",
    "        'Classifier (BC)', \n",
    "        'Total Bias (TB)', \n",
    "        'Observed Bias (mispred_p1)'\n",
    "    ]\n",
    "    \n",
    "    values = [\n",
    "        biases['BD'], \n",
    "         \n",
    "        biases['BSt-1'],\n",
    "        biases['St1-St2_Interaction'],\n",
    "        biases['BSt-2'], \n",
    "        biases['St2-St3_Interaction'], \n",
    "        \n",
    "        \n",
    "        biases['BSt-3'],\n",
    "        biases['St3_Classifier_Interaction'], \n",
    "        biases['BC'],\n",
    "        biases['TB'], \n",
    "        mispred_p1\n",
    "    ]\n",
    "\n",
    "    colors = [\n",
    "        'blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray'\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(labels, values, color=colors)\n",
    "    plt.xlabel('Bias / Mispredictions')\n",
    "    plt.title('Bias Analysis and Observed Mispredictions')\n",
    "\n",
    "    # Adding annotations\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        label_x_pos = width if width < 0 else width\n",
    "        plt.text(\n",
    "            label_x_pos, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{width:.2f}', ha='center', va='center',\n",
    "            bbox=dict(facecolor='white', alpha=0.7)\n",
    "        )\n",
    "\n",
    "    plt.axvline(0, color='black', linewidth=0.8)\n",
    "    plt.xlim(min(values) - 10, max(values) + 10)  # Adding some padding to the x-axis\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with hypothetical values\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test, y_pred_1, y_pred_2, y_pred_3 are defined\n",
    "mispred_p1 = sum(y_test != y_pred_1)\n",
    "mispred_p2 = sum(y_test != y_pred_2)\n",
    "mispred_p3 = sum(y_test != y_pred_3)\n",
    "mispred_p4 = sum(y_test != y_pred_4)\n",
    "\n",
    "\n",
    "\n",
    "# biases = calculate_biases_multiple(mispred_p1, mispred_p2, mispred_p3, mispred_p4, mispred_baseline)\n",
    "\n",
    "# Calculate biases\n",
    "biases = calculate_biases(mispred_p1, mispred_p2, mispred_p3,mispred_p4, mispred_baseline)\n",
    "plot_biases(biases, mispred_p1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_LE = np.zeros(len(y_test))\n",
    "volatility_SS = np.zeros(len(y_test))\n",
    "volatility_3 = np.zeros(len(y_test))\n",
    "volatility_classifier = np.zeros(len(y_test))\n",
    "\n",
    "# Volatility score calculation for PS1 (Preprocessing Stage 1)\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1[i] == y_test.iloc[i] and y_pred_2[i] == y_test.iloc[i]:\n",
    "        volatility_LE[i] = 0\n",
    "    elif y_pred_1[i] == y_test.iloc[i] and y_pred_2[i] != y_test.iloc[i]:\n",
    "        volatility_LE[i] = 1\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_2[i] == y_test.iloc[i]:\n",
    "        volatility_LE[i] = 2\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_2[i] != y_test.iloc[i] and y_pred_1[i] == y_pred_2[i]:\n",
    "        volatility_LE[i] = 3\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_2[i] != y_test.iloc[i] and y_pred_1[i] != y_pred_2[i]:\n",
    "        volatility_LE[i] = 4\n",
    "\n",
    "# Volatility score calculation for PS2 (Preprocessing Stage 2)\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1[i] == y_test.iloc[i] and y_pred_3[i] == y_test.iloc[i]:\n",
    "        volatility_SS[i] = 0\n",
    "    elif y_pred_1[i] == y_test.iloc[i] and y_pred_3[i] != y_test.iloc[i]:\n",
    "        volatility_SS[i] = 1\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_3[i] == y_test.iloc[i]:\n",
    "        volatility_SS[i] = 2\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_3[i] != y_test.iloc[i] and y_pred_1[i] == y_pred_3[i]:\n",
    "        volatility_SS[i] = 3\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_3[i] != y_test.iloc[i] and y_pred_1[i] != y_pred_3[i]:\n",
    "        volatility_SS[i] = 4\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1[i] == y_test.iloc[i] and y_pred_4[i] == y_test.iloc[i]:\n",
    "        volatility_3[i] = 0\n",
    "    elif y_pred_1[i] == y_test.iloc[i] and y_pred_4[i] != y_test.iloc[i]:\n",
    "        volatility_3[i] = 1\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_4[i] == y_test.iloc[i]:\n",
    "        volatility_3[i] = 2\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_4[i] != y_test.iloc[i] and y_pred_1[i] == y_pred_4[i]:\n",
    "        volatility_3[i] = 3\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_4[i] != y_test.iloc[i] and y_pred_1[i] != y_pred_4[i]:\n",
    "        volatility_3[i] = 4        \n",
    "        \n",
    "# Volatility score calculation for classifier\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1[i] == y_test.iloc[i] and y_pred_baseline[i] == y_test.iloc[i]:\n",
    "        volatility_classifier[i] = 0\n",
    "    elif y_pred_1[i] == y_test.iloc[i] and y_pred_baseline[i] != y_test.iloc[i]:\n",
    "        volatility_classifier[i] = 1\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_baseline[i] == y_test.iloc[i]:\n",
    "        volatility_classifier[i] = 2\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_baseline[i] != y_test.iloc[i] and y_pred_1[i] == y_pred_baseline[i]:\n",
    "        volatility_classifier[i] = 3\n",
    "    elif y_pred_1[i] != y_test.iloc[i] and y_pred_baseline[i] != y_test.iloc[i] and y_pred_1[i] != y_pred_baseline[i]:\n",
    "        volatility_classifier[i] = 4\n",
    "\n",
    "# Summarize volatility scores\n",
    "volatility_summary = {\n",
    "    'Condition': ['Vol_PS1=0', 'Vol_PS1=1', 'Vol_PS1=2', 'Vol_PS1=3', 'Vol_PS1=4',\n",
    "                  'Vol_PS2=0', 'Vol_PS2=1', 'Vol_PS2=2', 'Vol_PS2=3', 'Vol_PS2=4',\n",
    "                  'Vol_PS3=0', 'Vol_PS3=1', 'Vol_PS3=2', 'Vol_PS3=3', 'Vol_PS3=4',\n",
    "                  'Vol_Cl=0', 'Vol_Cl=1', 'Vol_Cl=2', 'Vol_Cl=3', 'Vol_Cl=4'],\n",
    "    'Count': [np.sum(volatility_LE == 0), np.sum(volatility_LE == 1), np.sum(volatility_LE == 2), np.sum(volatility_LE == 3), np.sum(volatility_LE == 4),\n",
    "              np.sum(volatility_SS == 0), np.sum(volatility_SS == 1), np.sum(volatility_SS == 2), np.sum(volatility_SS == 3), np.sum(volatility_SS == 4),\n",
    "              np.sum(volatility_3 == 0), np.sum(volatility_3 == 1), np.sum(volatility_3 == 2), np.sum(volatility_3 == 3), np.sum(volatility_3 == 4),\n",
    "\n",
    "              np.sum(volatility_classifier == 0), np.sum(volatility_classifier == 1), np.sum(volatility_classifier == 2), np.sum(volatility_classifier == 3), np.sum(volatility_classifier == 4)]\n",
    "}\n",
    "\n",
    "df_volatility = pd.DataFrame(volatility_summary)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(x='Condition', y='Count', data=df_volatility, palette='viridis')\n",
    "\n",
    "plt.title('Volatility Score Analysis')\n",
    "\n",
    "plt.xlabel('Condition')\n",
    "plt.xticks(rotation=75)  # Rotate labels by 45 degrees\n",
    "\n",
    "plt.ylabel('Count')\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, fmt='%.0f', label_type='edge')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b181f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Tuple, Any, Optional\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Optional: SMOTE if you plan to oversample (safe fallback if not installed)\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE  # noqa\n",
    "except Exception:\n",
    "    SMOTE = None  # oversampling step will be skipped if None\n",
    "\n",
    "\n",
    "# ---------- Mitigation framework (no hard-coding of stages) ----------\n",
    "MitigationFn = Callable[\n",
    "    [Any, np.ndarray, np.ndarray, Dict[str, Any]],\n",
    "    Tuple[Any, np.ndarray, np.ndarray, Dict[str, Any]]\n",
    "]\n",
    "# Signature: fn(pipeline, X_train, y_train, context) -> (pipeline, X_train, y_train, fit_params_delta)\n",
    "\n",
    "def run_mitigations_and_predict(\n",
    "    pipeline: Any,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test:  np.ndarray,\n",
    "    y_test:  Optional[np.ndarray] = None,\n",
    "    mitigations: Optional[List[Dict[str, Any]]] = None,\n",
    "    base_fit_params: Optional[Dict[str, Any]] = None,\n",
    "    context: Optional[Dict[str, Any]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fits pipeline, applies mitigation callables, then refits and re-predicts.\n",
    "    Returns pre/post metrics & predictions. No random post-hoc tweaks.\n",
    "    \"\"\"\n",
    "    base_fit_params = dict(base_fit_params or {})\n",
    "    context = dict(context or {})\n",
    "    mitigations = mitigations or []\n",
    "\n",
    "    # 1) Baseline fit & predict (pre-mitigation)\n",
    "    pipeline.fit(X_train, y_train, **base_fit_params)\n",
    "    y_pred_pre = pipeline.predict(X_test)\n",
    "\n",
    "    metrics_pre = {}\n",
    "    if y_test is not None:\n",
    "        metrics_pre[\"accuracy\"] = float(accuracy_score(y_test, y_pred_pre))\n",
    "\n",
    "    # 2) Apply mitigations (may update pipeline/data/fit_params)\n",
    "    applied = []\n",
    "    X_train_m, y_train_m = X_train, y_train\n",
    "    fit_params = dict(base_fit_params)\n",
    "\n",
    "    for step in mitigations:\n",
    "        name = step.get(\"name\", \"<unnamed>\")\n",
    "        fn: MitigationFn = step[\"fn\"]\n",
    "        params = step.get(\"params\", {})\n",
    "        ctx = dict(context); ctx.update(params)\n",
    "\n",
    "        pipeline, X_train_m, y_train_m, delta = fn(pipeline, X_train_m, y_train_m, ctx)\n",
    "        if delta:\n",
    "            fit_params.update(delta)\n",
    "        applied.append({\"name\": name, \"fit_params_delta_keys\": list((delta or {}).keys())})\n",
    "\n",
    "    # 3) Refit post-mitigation & predict\n",
    "    pipeline.fit(X_train_m, y_train_m, **fit_params)\n",
    "    y_pred_post = pipeline.predict(X_test)\n",
    "\n",
    "    metrics_post = {}\n",
    "    if y_test is not None:\n",
    "        metrics_post[\"accuracy\"] = float(accuracy_score(y_test, y_pred_post))\n",
    "\n",
    "    return {\n",
    "        \"y_pred_pre\": y_pred_pre,\n",
    "        \"y_pred_post\": y_pred_post,\n",
    "        \"metrics_pre\": metrics_pre,\n",
    "        \"metrics_post\": metrics_post,\n",
    "        \"applied_mitigations\": applied,\n",
    "        \"pipeline_final\": pipeline\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- Example mitigation primitives (compose as you like) ----------\n",
    "def mitigation_reweighing(pipeline, X_train, y_train, context):\n",
    "    \"\"\"\n",
    "    Adds per-sample weights into fit params (no data mutation).\n",
    "    Provide either:\n",
    "      - context[\"sample_weights\"] (np.ndarray aligned with y_train), or\n",
    "      - context[\"weight_fn\"](X_train, y_train, context) -> np.ndarray\n",
    "    You can change which estimator receives weights via context[\"weight_param\"]\n",
    "      e.g., \"classifier__sample_weight\" or \"clf__sample_weight\".\n",
    "    \"\"\"\n",
    "    if \"sample_weights\" in context:\n",
    "        w = np.asarray(context[\"sample_weights\"])\n",
    "    elif callable(context.get(\"weight_fn\", None)):\n",
    "        w = np.asarray(context[\"weight_fn\"](X_train, y_train, context))\n",
    "    else:\n",
    "        raise ValueError(\"mitigation_reweighing needs 'sample_weights' or 'weight_fn' in context.\")\n",
    "\n",
    "    target_param = context.get(\"weight_param\", \"classifier__sample_weight\")\n",
    "    return pipeline, X_train, y_train, {target_param: w}\n",
    "\n",
    "\n",
    "def mitigation_oversample(pipeline, X_train, y_train, context):\n",
    "    \"\"\"\n",
    "    Uses a provided oversampler (e.g., SMOTE) from context[\"oversampler\"].\n",
    "    \"\"\"\n",
    "    oversampler = context.get(\"oversampler\", None)\n",
    "    if oversampler is None:\n",
    "        # If SMOTE not available or not provided, leave data unchanged\n",
    "        return pipeline, X_train, y_train, {}\n",
    "    X_res, y_res = oversampler.fit_resample(X_train, y_train)\n",
    "    return pipeline, X_res, y_res, {}\n",
    "\n",
    "\n",
    "def mitigation_encoder_tweak(pipeline, X_train, y_train, context):\n",
    "    \"\"\"\n",
    "    Placeholder to swap/modify an encoder inside your pipeline if needed.\n",
    "    Example:\n",
    "      pipeline.set_params(preprocess__encoder=YourEncoder(**context.get(\"encoder_params\", {})))\n",
    "    \"\"\"\n",
    "    return pipeline, X_train, y_train, {}\n",
    "\n",
    "\n",
    "# ---------- A simple, sensible reweighting function (group × label inverse prevalence) ----------\n",
    "def inverse_prevalence_weights(X, y, ctx):\n",
    "    \"\"\"\n",
    "    Compute weights ~ 1 / P(y, s) using ctx[\"s_train\"] (sensitive attribute, aligned with y).\n",
    "    \"\"\"\n",
    "    s = np.asarray(ctx.get(\"s_train\", None))\n",
    "    if s is None:\n",
    "        raise ValueError(\"inverse_prevalence_weights requires 's_train' in context.\")\n",
    "    y = np.asarray(y)\n",
    "    pairs, counts = np.unique(np.column_stack([y, s]), axis=0, return_counts=True)\n",
    "    freq = {tuple(k): v for k, v in zip(map(tuple, pairs), counts)}\n",
    "    total = len(y)\n",
    "    w = np.empty_like(y, dtype=float)\n",
    "    for i, (yy, ss) in enumerate(zip(y, s)):\n",
    "        p = freq[(yy, ss)] / total\n",
    "        w[i] = 1.0 / max(p, 1e-12)\n",
    "    # Normalize to mean 1.0 (optional)\n",
    "    w /= w.mean()\n",
    "    return w\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PRODUCE THE NEW PREDICTIONS\n",
    "# =========================\n",
    "# Assumptions: you already have:\n",
    "#   pipeline_1, pipeline_2, pipeline_3  (sklearn Pipelines/estimators)\n",
    "#   X_train, y_train, X_test, y_test     (arrays/Series)\n",
    "#   s_train                               (sensitive attribute aligned with y_train)\n",
    "#\n",
    "# If you don't want oversampling, just remove the mitigation_oversample step below.\n",
    "\n",
    "mitigations_cfg = [\n",
    "    {\"name\": \"Reweighing\", \"fn\": mitigation_reweighing,\n",
    "     \"params\": {\n",
    "         \"weight_param\": \"classifier__sample_weight\",   # adjust to your pipeline\n",
    "         \"weight_fn\": inverse_prevalence_weights\n",
    "     }},\n",
    "    {\"name\": \"Oversample\", \"fn\": mitigation_oversample,\n",
    "     \"params\": {\"oversampler\": SMOTE(random_state=42) if SMOTE is not None else None}},\n",
    "    {\"name\": \"Encoder tweak\", \"fn\": mitigation_encoder_tweak, \"params\": {}},\n",
    "]\n",
    "\n",
    "common_context = {\"s_train\": s_train, \"seed\": 42}\n",
    "\n",
    "res_1 = run_mitigations_and_predict(\n",
    "    pipeline=pipeline_1,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test,  y_test=y_test,\n",
    "    mitigations=mitigations_cfg,\n",
    "    base_fit_params={},\n",
    "    context=common_context\n",
    ")\n",
    "y_pred_1n = res_1[\"y_pred_post\"]\n",
    "\n",
    "res_2 = run_mitigations_and_predict(\n",
    "    pipeline=pipeline_2,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test,  y_test=y_test,\n",
    "    mitigations=mitigations_cfg,\n",
    "    base_fit_params={},\n",
    "    context=common_context\n",
    ")\n",
    "y_pred_2n = res_2[\"y_pred_post\"]\n",
    "\n",
    "res_3 = run_mitigations_and_predict(\n",
    "    pipeline=pipeline_3,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test,  y_test=y_test,\n",
    "    mitigations=mitigations_cfg,\n",
    "    base_fit_params={},\n",
    "    context=common_context\n",
    ")\n",
    "y_pred_3n = res_3[\"y_pred_post\"]\n",
    "\n",
    "res_4 = run_mitigations_and_predict(\n",
    "    pipeline=pipeline_4,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test,  y_test=y_test,\n",
    "    mitigations=mitigations_cfg,\n",
    "    base_fit_params={},\n",
    "    context=common_context\n",
    ")\n",
    "y_pred_4n = res_4[\"y_pred_post\"]\n",
    "\n",
    "# (Optional) Inspect honest pre/post metrics:\n",
    "# print(res_1[\"metrics_pre\"], res_1[\"metrics_post\"])\n",
    "# print(res_2[\"metrics_pre\"], res_2[\"metrics_post\"])\n",
    "# print(res_3[\"metrics_pre\"], res_3[\"metrics_post\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2214fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, List, Tuple, Any, Optional, Sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers for stage outputs\n",
    "# =========================\n",
    "def _truncate_pipeline(pipeline, stage_name: str):\n",
    "    \"\"\"\n",
    "    Return a shallow-cloned pipeline that runs up to and including `stage_name`.\n",
    "    Special names:\n",
    "      - \"__raw__\": no transform, just return raw X\n",
    "      - \"__end__\": full pipeline\n",
    "    \"\"\"\n",
    "    if stage_name == \"__raw__\":\n",
    "        return None\n",
    "    if stage_name == \"__end__\":\n",
    "        return clone(pipeline)\n",
    "    steps = []\n",
    "    for name, est in pipeline.steps:\n",
    "        steps.append((name, est))\n",
    "        if name == stage_name:\n",
    "            break\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    return Pipeline(steps=steps)\n",
    "\n",
    "def _fit_transform_at_stage(pipeline, X: pd.DataFrame, stage_name: str) -> pd.DataFrame:\n",
    "    if stage_name == \"__raw__\":\n",
    "        return _ensure_df(X)\n",
    "    tp = _truncate_pipeline(pipeline, stage_name)\n",
    "    if tp is None:\n",
    "        return _ensure_df(X)\n",
    "    try:\n",
    "        tp.set_output(transform=\"pandas\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    Xt = tp.fit_transform(X)\n",
    "    return _ensure_df(Xt)\n",
    "\n",
    "def _ensure_df(X) -> pd.DataFrame:\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return X\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        X = X.toarray()\n",
    "    if isinstance(X, np.ndarray):\n",
    "        return pd.DataFrame(X, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "    return pd.DataFrame(X)\n",
    "\n",
    "def _expand_attributes_in_transformed(X_after: pd.DataFrame, attributes: Sequence[str]) -> List[str]:\n",
    "    \"\"\"Map requested raw attributes to transformed columns (handles one-hot by substring match).\"\"\"\n",
    "    cols = []\n",
    "    for a in attributes:\n",
    "        a_low = str(a).lower()\n",
    "        for c in X_after.columns:\n",
    "            if a_low in str(c).lower():\n",
    "                cols.append(c)\n",
    "    if not cols:\n",
    "        cols = [c for c in X_after.columns if c in attributes]\n",
    "    # dedupe\n",
    "    seen, out = set(), []\n",
    "    for c in cols:\n",
    "        if c not in seen:\n",
    "            out.append(c); seen.add(c)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 1) Correlations before vs after any stage\n",
    "# ===========================================\n",
    "def compare_attribute_correlations(\n",
    "    pipeline,\n",
    "    X: pd.DataFrame,\n",
    "    attributes: Sequence[str],\n",
    "    stage_name: str,\n",
    "    method: str = \"pearson\",\n",
    "    figsize: Tuple[int, int] = (10, 4)\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute & display correlation matrices for selected `attributes`\n",
    "    BEFORE vs AFTER a given preprocessing `stage_name`.\n",
    "    stage_name: \"__raw__\" | any pipeline step name | \"__end__\"\n",
    "    \"\"\"\n",
    "    X_before = _ensure_df(X)\n",
    "    X_after  = _fit_transform_at_stage(pipeline, X, stage_name)\n",
    "\n",
    "    before_cols = [c for c in X_before.columns if c in attributes]\n",
    "    after_cols  = _expand_attributes_in_transformed(X_after, attributes)\n",
    "\n",
    "    corr_before = _ensure_df(X_before[before_cols]).corr(method=method) if before_cols else pd.DataFrame()\n",
    "    corr_after  = _ensure_df(X_after[after_cols]).corr(method=method)   if after_cols  else pd.DataFrame()\n",
    "\n",
    "    if not corr_before.empty:\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(corr_before, interpolation=\"nearest\")\n",
    "        plt.xticks(range(len(corr_before.columns)), corr_before.columns, rotation=90)\n",
    "        plt.yticks(range(len(corr_before.index)), corr_before.index)\n",
    "        plt.title(f\"Correlation BEFORE stage '{stage_name}' ({method})\")\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if not corr_after.empty:\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(corr_after, interpolation=\"nearest\")\n",
    "        plt.xticks(range(len(corr_after.columns)), corr_after.columns, rotation=90)\n",
    "        plt.yticks(range(len(corr_after.index)), corr_after.index)\n",
    "        plt.title(f\"Correlation AFTER stage '{stage_name}' ({method})\")\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return {\"before\": corr_before, \"after\": corr_after}\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 2) Feature distribution before vs after any stage\n",
    "# ==================================================\n",
    "def compare_feature_distribution(\n",
    "    pipeline,\n",
    "    X: pd.DataFrame,\n",
    "    feature: str,\n",
    "    stage_name: str,\n",
    "    bins: int = 20,\n",
    "    top_k_categories: int = 25,\n",
    "    figsize: Tuple[int, int] = (8, 4)\n",
    ") -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    Display the distribution of a single `feature` BEFORE vs AFTER `stage_name`.\n",
    "    Numeric => histogram; Categorical => top-k bar counts.\n",
    "    If transformed into multiple one-hot columns, aggregate those columns into a categorical count vector.\n",
    "    \"\"\"\n",
    "    X_before = _ensure_df(X).copy()\n",
    "    X_after  = _fit_transform_at_stage(pipeline, X, stage_name)\n",
    "\n",
    "    # BEFORE\n",
    "    if feature in X_before.columns:\n",
    "        series_before = X_before[feature]\n",
    "    else:\n",
    "        matches = [c for c in X_before.columns if c.lower() == feature.lower()]\n",
    "        series_before = X_before[matches[0]] if matches else pd.Series(dtype=float, name=feature)\n",
    "\n",
    "    # AFTER (map to columns)\n",
    "    after_cols = _expand_attributes_in_transformed(X_after, [feature])\n",
    "\n",
    "    if len(after_cols) == 0:\n",
    "        series_after = pd.Series(dtype=float, name=feature)\n",
    "    elif len(after_cols) == 1 and after_cols[0] in X_after.columns:\n",
    "        series_after = X_after[after_cols[0]]\n",
    "    else:\n",
    "        sub = X_after[after_cols]\n",
    "        cat_names = [c.replace(f\"{feature}_\", \"\") for c in sub.columns]\n",
    "        counts = sub.apply(pd.Series.sum, axis=0)\n",
    "        counts.index = cat_names\n",
    "        series_after = counts\n",
    "\n",
    "    # Plot BEFORE\n",
    "    if pd.api.types.is_numeric_dtype(series_before):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.hist(series_before.dropna(), bins=bins)\n",
    "        plt.title(f\"Distribution BEFORE stage '{stage_name}' — {feature}\")\n",
    "        plt.xlabel(feature); plt.ylabel(\"count\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "        dist_before = series_before\n",
    "    else:\n",
    "        vc = series_before.astype(\"object\").fillna(\"<NA>\").value_counts().sort_values(ascending=False)\n",
    "        vc = vc.head(top_k_categories)\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.bar(vc.index.astype(str), vc.values)\n",
    "        plt.title(f\"Distribution BEFORE stage '{stage_name}' — {feature}\")\n",
    "        plt.xticks(rotation=90); plt.ylabel(\"count\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "        dist_before = vc\n",
    "\n",
    "    # Plot AFTER\n",
    "    if isinstance(series_after, pd.Series) and pd.api.types.is_numeric_dtype(series_after) and series_after.shape[0] == X_after.shape[0]:\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.hist(series_after.dropna(), bins=bins)\n",
    "        plt.title(f\"Distribution AFTER stage '{stage_name}' — {feature}\")\n",
    "        plt.xlabel(feature); plt.ylabel(\"count\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "        dist_after = series_after\n",
    "    else:\n",
    "        if isinstance(series_after, pd.Series) and series_after.index.size > 0:\n",
    "            counts = series_after.sort_values(ascending=False).head(top_k_categories)\n",
    "            plt.figure(figsize=figsize)\n",
    "            plt.bar(counts.index.astype(str), counts.values)\n",
    "            plt.title(f\"Distribution AFTER stage '{stage_name}' — {feature} (aggregated)\")\n",
    "            plt.xticks(rotation=90); plt.ylabel(\"count\")\n",
    "            plt.tight_layout(); plt.show()\n",
    "            dist_after = counts\n",
    "        else:\n",
    "            dist_after = pd.Series(dtype=float, name=feature)\n",
    "\n",
    "    return {\"before\": dist_before, \"after\": dist_after}\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 3) Threshold guard that calls YOUR mitigation function\n",
    "#    - Uses your Fairness_Metrics_Computation(...)\n",
    "#    - Calls your run_mitigations_and_predict(...) if violated\n",
    "# ==========================================================\n",
    "def _check_thresholds(metrics: Dict[str, float], thresholds: Dict[str, Tuple]) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if ANY threshold is violated.\n",
    "    thresholds[k] = (op, val) or (\"between\", lo, hi)\n",
    "    \"\"\"\n",
    "    def violated_one(metric, rule):\n",
    "        op = rule[0]\n",
    "        vals = rule[1:]\n",
    "        m = metrics.get(metric, None)\n",
    "        if m is None:\n",
    "            return False\n",
    "        if op == \">=\":   return not (m >= vals[0])\n",
    "        if op == \"<=\":   return not (m <= vals[0])\n",
    "        if op == \">\":    return not (m >  vals[0])\n",
    "        if op == \"<\":    return not (m <  vals[0])\n",
    "        if op == \"between\":\n",
    "            lo, hi = vals\n",
    "            return not (lo <= m <= hi)\n",
    "        raise ValueError(f\"Unknown threshold op: {op}\")\n",
    "    return any(violated_one(k, v) for k, v in thresholds.items())\n",
    "\n",
    "def guard_and_mitigate_if_needed(\n",
    "    pipeline,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: np.ndarray,\n",
    "    sensitive_attr_test: np.ndarray,\n",
    "    thresholds: Dict[str, Tuple],\n",
    "    # ex:\n",
    "    # thresholds = {\n",
    "    #   \"accuracy\": (\">=\", 0.85),\n",
    "    #   \"disparate_impact_ratio\": (\">=\", 0.8),\n",
    "    #   \"demographic_parity_diff\": (\"between\", -0.1, 0.1)\n",
    "    # }\n",
    "    mitigations_cfg: List[Dict[str, Any]],\n",
    "    context: Dict[str, Any],\n",
    "    base_fit_params: Optional[Dict[str, Any]] = None,\n",
    "    fairness_compute_type: str = \"global\",\n",
    "    y2_scores: Optional[np.ndarray] = None,\n",
    "    positive_label=1\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    1) Fit the baseline pipeline and compute metrics\n",
    "       - Accuracy via sklearn\n",
    "       - Fairness via your Fairness_Metrics_Computation(y1, y2, y, attribute, compute_type)\n",
    "         (y1 = y_pred, y2 = y2_scores or None, y = y_test, attribute = sensitive_attr_test)\n",
    "    2) If ANY threshold is violated, call your run_mitigations_and_predict(...)\n",
    "    3) Return both pre/post metrics and final predictions\n",
    "    \"\"\"\n",
    "    base_fit_params = dict(base_fit_params or {})\n",
    "    model = clone(pipeline)\n",
    "    model.fit(X_train, y_train, **base_fit_params)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # --- metrics (accuracy + fairness) ---\n",
    "    metrics = {\"accuracy\": float(accuracy_score(y_test, y_pred))}\n",
    "    fairness_dict = Fairness_Metrics_Computation(\n",
    "        y1=y_pred, y2=y2_scores, y=y_test, attribute=sensitive_attr_test, compute_type=fairness_compute_type\n",
    "    )\n",
    "    # Merge fairness metrics into metrics dict\n",
    "    metrics.update({k: float(v) for k, v in fairness_dict.items()})\n",
    "\n",
    "    violated = _check_thresholds(metrics, thresholds)\n",
    "\n",
    "    result = {\n",
    "        \"violated\": violated,\n",
    "        \"metrics_pre\": metrics,\n",
    "        \"y_pred_pre\": y_pred,\n",
    "        \"pipeline_pre\": model\n",
    "    }\n",
    "\n",
    "    if not violated:\n",
    "        result.update({\n",
    "            \"used_post_mitigation\": False,\n",
    "            \"y_pred_final\": y_pred,\n",
    "            \"metrics_final\": metrics,\n",
    "            \"pipeline_final\": model\n",
    "        })\n",
    "        return result\n",
    "\n",
    "    # --- run your mitigation routine (already defined in your codebase) ---\n",
    "    mit_res = run_mitigations_and_predict(\n",
    "        pipeline=model,\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        X_test=X_test,  y_test=y_test,\n",
    "        mitigations=mitigations_cfg,\n",
    "        base_fit_params=base_fit_params,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    # recompute fairness on post-mitigation predictions for apples-to-apples\n",
    "    y_pred_post = mit_res[\"y_pred_post\"]\n",
    "    metrics_post = {\"accuracy\": float(accuracy_score(y_test, y_pred_post))}\n",
    "    fairness_post = Fairness_Metrics_Computation(\n",
    "        y1=y_pred_post, y2=y2_scores, y=y_test, attribute=sensitive_attr_test, compute_type=fairness_compute_type\n",
    "    )\n",
    "    metrics_post.update({k: float(v) for k, v in fairness_post.items()})\n",
    "\n",
    "    result.update({\n",
    "        \"used_post_mitigation\": True,\n",
    "        \"mitigation_detail\": mit_res.get(\"applied_mitigations\", []),\n",
    "        \"y_pred_post\": y_pred_post,\n",
    "        \"metrics_post\": metrics_post,\n",
    "        \"y_pred_final\": y_pred_post,\n",
    "        \"metrics_final\": metrics_post,\n",
    "        \"pipeline_final\": mit_res[\"pipeline_final\"],\n",
    "    })\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_attribute_correlations(\n",
    "    pipeline=pipeline_1,\n",
    "    X=X_train,\n",
    "    attributes=[\"sex\"],\n",
    "    stage_name=\"preprocess\"    # or \"__raw__\", \"__end__\", or any step name in your pipeline\n",
    ")\n",
    "\n",
    "\n",
    "compare_feature_distribution(\n",
    "    pipeline=pipeline_2,\n",
    "    X=X_train,\n",
    "    feature=\"education\",\n",
    "    stage_name=\"preprocess\"\n",
    ")\n",
    "\n",
    "thresholds = {\n",
    "    \"accuracy\": (\">=\", 0.85),\n",
    "    \"disparate_impact_ratio\": (\">=\", 0.8),\n",
    "    \"demographic_parity_diff\": (\"between\", -0.1, 0.1),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ce102",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1n= accuracy_score(y_test, y_pred_1n)\n",
    "A2n= accuracy_score(y_test, y_pred_2n)\n",
    "f1n = f1_score(y_test, y_pred_1n)\n",
    "f2n=f1_score(y_test, y_pred_2n)\n",
    "\n",
    "A3n= accuracy_score(y_test, y_pred_3n)\n",
    "A4n= accuracy_score(y_test, y_pred_4n)\n",
    "f3n = f1_score(y_test, y_pred_3n)\n",
    "f4n=f1_score(y_test, y_pred_4n)\n",
    "A1, A1n,A2, A2n,A3, A3n, A4, A4n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a84a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf268e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=X['age'])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "def calculate_biases(mispred_p1, mispred_p2, mispred_p3,mispred_p4, mispred_baseline):\n",
    "    \"\"\"\n",
    "    Calculate individual biases and total bias.\n",
    "\n",
    "    Parameters:\n",
    "    mispred_p1 (int): Mispredictions for P1 (LE+SS+Classifier)\n",
    "    mispred_p2 (int): Mispredictions for P2 (SS+Classifier)\n",
    "    mispred_p3 (int): Mispredictions for P3 (LE+Classifier)\n",
    "    mispred_baseline (int): Mispredictions for the baseline model\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the individual biases and total bias\n",
    "    \"\"\"\n",
    "    # Calculating individual biases\n",
    "    BD = mispred_baseline\n",
    "    BLE = mispred_p1 - mispred_p2\n",
    "    LE_SS_Interaction = mispred_p1 - (mispred_p2 + mispred_p3 - mispred_baseline)\n",
    "\n",
    "    BSS = mispred_p1 - mispred_p3\n",
    "    SS_PC_Interaction = mispred_p1 - (mispred_p2 + mispred_p4 - mispred_baseline)\n",
    "    \n",
    "    BPC = mispred_p1 - mispred_p4\n",
    "    PC_Classifier_Interaction = mispred_p1 - (mispred_p3 + mispred_p4 - mispred_baseline)\n",
    "\n",
    "    # Calculate BC to ensure TB equals mispred_p1\n",
    "    BC = mispred_p1 - (BD + BLE + BSS + BPC + LE_SS_Interaction + SS_PC_Interaction + PC_Classifier_Interaction)\n",
    "\n",
    "    # Calculate the total bias\n",
    "    TB = BD + BLE + BSS + BPC + BC + LE_SS_Interaction + SS_PC_Interaction + PC_Classifier_Interaction\n",
    "\n",
    "    # Returning the results as a dictionary\n",
    "    return {\n",
    "        'BD': BD,\n",
    "\n",
    "        'BSt-1': BLE,\n",
    "        'St1-St2_Interaction': LE_SS_Interaction,\n",
    "        'BSt-2': BSS,\n",
    "        'St2-St3_Interaction': SS_PC_Interaction,\n",
    "        'BSt-3': BPC,\n",
    "              \n",
    "        'St3_Classifier_Interaction': PC_Classifier_Interaction,\n",
    "        'BC': BC,\n",
    "        'TB': TB\n",
    "    }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_biases(biases, mispred_p1):\n",
    "    \"\"\"\n",
    "    Plot biases and observed mispredictions.\n",
    "    \"\"\"\n",
    "    labels = [\n",
    "        'Data (BD)', \n",
    "        \n",
    "        'Preprocessing Stage 1', \n",
    "        'Stage 1-2 Interaction',\n",
    "        'Preprocessing Stage 2', \n",
    "         \n",
    "       \n",
    "        'Stage 2-3 Interaction',\n",
    "        'Preprocessing Stage 3',\n",
    "        'Stage 3-Classifier Interaction',\n",
    "        'Classifier (BC)', \n",
    "        'Total Bias (TB)', \n",
    "        'Observed Bias (mispred_p1)'\n",
    "    ]\n",
    "    \n",
    "    values = [\n",
    "        biases['BD'], \n",
    "         \n",
    "        biases['BSt-1'],\n",
    "        biases['St1-St2_Interaction'],\n",
    "        biases['BSt-2'], \n",
    "        biases['St2-St3_Interaction'], \n",
    "        \n",
    "        \n",
    "        biases['BSt-3'],\n",
    "        biases['St3_Classifier_Interaction'], \n",
    "        biases['BC'],\n",
    "        biases['TB'], \n",
    "        mispred_p1\n",
    "    ]\n",
    "\n",
    "    colors = [\n",
    "        'blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray'\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(labels, values, color=colors)\n",
    "    plt.xlabel('Bias / Mispredictions')\n",
    "    plt.title('Bias Analysis and Observed Mispredictions - After Mitigation')\n",
    "\n",
    "    # Adding annotations\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        label_x_pos = width if width < 0 else width\n",
    "        plt.text(\n",
    "            label_x_pos, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{width:.2f}', ha='center', va='center',\n",
    "            bbox=dict(facecolor='white', alpha=0.7)\n",
    "        )\n",
    "\n",
    "    plt.axvline(0, color='black', linewidth=0.8)\n",
    "    plt.xlim(min(values) - 10, max(values) + 10)  # Adding some padding to the x-axis\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with hypothetical values\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test, y_pred_1, y_pred_2, y_pred_3 are defined\n",
    "mispred_p1 = sum(y_test != y_pred_1n)\n",
    "mispred_p2 = sum(y_test != y_pred_2n)\n",
    "mispred_p3 = sum(y_test != y_pred_3n)\n",
    "mispred_p4 = sum(y_test != y_pred_4n)\n",
    "\n",
    "\n",
    "\n",
    "# biases = calculate_biases_multiple(mispred_p1, mispred_p2, mispred_p3, mispred_p4, mispred_baseline)\n",
    "\n",
    "# Calculate biases\n",
    "biases = calculate_biases(mispred_p1, mispred_p2, mispred_p3,mispred_p4, mispred_baseline)\n",
    "plot_biases(biases, mispred_p1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_LE = np.zeros(len(y_test))\n",
    "volatility_SS = np.zeros(len(y_test))\n",
    "volatility_3 = np.zeros(len(y_test))\n",
    "volatility_classifier = np.zeros(len(y_test))\n",
    "\n",
    "# Volatility score calculation for PS1 (Preprocessing Stage 1)\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1n[i] == y_test.iloc[i] and y_pred_2n[i] == y_test.iloc[i]:\n",
    "        volatility_LE[i] = 0\n",
    "    elif y_pred_1n[i] == y_test.iloc[i] and y_pred_2n[i] != y_test.iloc[i]:\n",
    "        volatility_LE[i] = 1\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_2n[i] == y_test.iloc[i]:\n",
    "        volatility_LE[i] = 2\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_2n[i] != y_test.iloc[i] and y_pred_1n[i] == y_pred_2n[i]:\n",
    "        volatility_LE[i] = 3\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_2n[i] != y_test.iloc[i] and y_pred_1n[i] != y_pred_2n[i]:\n",
    "        volatility_LE[i] = 4\n",
    "\n",
    "# Volatility score calculation for PS2 (Preprocessing Stage 2)\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1n[i] == y_test.iloc[i] and y_pred_3n[i] == y_test.iloc[i]:\n",
    "        volatility_SS[i] = 0\n",
    "    elif y_pred_1n[i] == y_test.iloc[i] and y_pred_3n[i] != y_test.iloc[i]:\n",
    "        volatility_SS[i] = 1\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_3n[i] == y_test.iloc[i]:\n",
    "        volatility_SS[i] = 2\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_3n[i] != y_test.iloc[i] and y_pred_1n[i] == y_pred_3n[i]:\n",
    "        volatility_SS[i] = 3\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_3n[i] != y_test.iloc[i] and y_pred_1n[i] != y_pred_3n[i]:\n",
    "        volatility_SS[i] = 4\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1n[i] == y_test.iloc[i] and y_pred_4n[i] == y_test.iloc[i]:\n",
    "        volatility_3[i] = 0\n",
    "    elif y_pred_1n[i] == y_test.iloc[i] and y_pred_4n[i] != y_test.iloc[i]:\n",
    "        volatility_3[i] = 1\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_4n[i] == y_test.iloc[i]:\n",
    "        volatility_3[i] = 2\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_4n[i] != y_test.iloc[i] and y_pred_1n[i] == y_pred_4n[i]:\n",
    "        volatility_3[i] = 3\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_4n[i] != y_test.iloc[i] and y_pred_1n[i] != y_pred_4[i]:\n",
    "        volatility_3[i] = 4        \n",
    "        \n",
    "# Volatility score calculation for classifier\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_1n[i] == y_test.iloc[i] and y_pred_baseline[i] == y_test.iloc[i]:\n",
    "        volatility_classifier[i] = 0\n",
    "    elif y_pred_1n[i] == y_test.iloc[i] and y_pred_baseline[i] != y_test.iloc[i]:\n",
    "        volatility_classifier[i] = 1\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_baseline[i] == y_test.iloc[i]:\n",
    "        volatility_classifier[i] = 2\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_baseline[i] != y_test.iloc[i] and y_pred_1n[i] == y_pred_baseline[i]:\n",
    "        volatility_classifier[i] = 3\n",
    "    elif y_pred_1n[i] != y_test.iloc[i] and y_pred_baseline[i] != y_test.iloc[i] and y_pred_1n[i] != y_pred_baseline[i]:\n",
    "        volatility_classifier[i] = 4\n",
    "\n",
    "# Summarize volatility scores\n",
    "volatility_summary = {\n",
    "    'Condition': ['Vol_PS1=0', 'Vol_PS1=1', 'Vol_PS1=2', 'Vol_PS1=3', 'Vol_PS1=4',\n",
    "                  'Vol_PS2=0', 'Vol_PS2=1', 'Vol_PS2=2', 'Vol_PS2=3', 'Vol_PS2=4',\n",
    "                  'Vol_PS3=0', 'Vol_PS3=1', 'Vol_PS3=2', 'Vol_PS3=3', 'Vol_PS3=4',\n",
    "                  'Vol_Cl=0', 'Vol_Cl=1', 'Vol_Cl=2', 'Vol_Cl=3', 'Vol_Cl=4'],\n",
    "    'Count': [np.sum(volatility_LE == 0), np.sum(volatility_LE == 1), np.sum(volatility_LE == 2), np.sum(volatility_LE == 3), np.sum(volatility_LE == 4),\n",
    "              np.sum(volatility_SS == 0), np.sum(volatility_SS == 1), np.sum(volatility_SS == 2), np.sum(volatility_SS == 3), np.sum(volatility_SS == 4),\n",
    "              np.sum(volatility_3 == 0), np.sum(volatility_3 == 1), np.sum(volatility_3 == 2), np.sum(volatility_3 == 3), np.sum(volatility_3 == 4),\n",
    "\n",
    "              np.sum(volatility_classifier == 0), np.sum(volatility_classifier == 1), np.sum(volatility_classifier == 2), np.sum(volatility_classifier == 3), np.sum(volatility_classifier == 4)]\n",
    "}\n",
    "\n",
    "df_volatility = pd.DataFrame(volatility_summary)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(x='Condition', y='Count', data=df_volatility, palette='viridis')\n",
    "\n",
    "plt.title('Volatility Score Analysis -After Mitigation')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=75)\n",
    "\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, fmt='%.0f', label_type='edge')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d56815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "347+66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0fc41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c57a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Function to calculate accuracy and F1 score\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, f1\n",
    "\n",
    "# Example computed metrics for illustration\n",
    "accuracy_1= A1\n",
    "accuracy_2 = np.abs(A1- A2)\n",
    "accuracy_3= np.abs(A1- A3)\n",
    "accuracy_4 = np.abs(A1- A4)\n",
    "\n",
    "accuracy_1n = A1n \n",
    "accuracy_2n = np.abs(A1n-A2n)  # After mitigation accuracies\n",
    "accuracy_3n = np.abs(A1n-A3n)  # After mitigation accuracies\n",
    "accuracy_4n = np.abs(A1n-A4n)  # After mitigation accuracies\n",
    "\n",
    "\n",
    "f1_1 = f1\n",
    "f1_2 = np.abs(f1-f2)\n",
    "f1_3 = np.abs(f1-f3)\n",
    "f1_4 = np.abs(f1-f4)\n",
    "\n",
    "\n",
    "f1_1n= f1n\n",
    "f1_2n =np.abs(f1n-f2n)\n",
    "f1_3n =np.abs(f1n-f3n)\n",
    "f1_4n =np.abs(f1n-f4n)\n",
    "\n",
    "\n",
    "# Function to plot the accuracy and F1 scores for pipelines and components before and after mitigation\n",
    "def plot_metrics():\n",
    "    labels = ['Pipeline', 'FS Component', 'Stratification Component', 'SS Component']  # Update this if needed for component names\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    before_mitigation_accuracy = [accuracy_1, accuracy_2n,accuracy_3n, accuracy_4]\n",
    "    after_mitigation_accuracy = [accuracy_1n, accuracy_2,accuracy_3, accuracy_4n]\n",
    "    \n",
    "    \n",
    "    bar_width = 0.35  # Width of the bars\n",
    "    x = np.arange(len(labels))\n",
    "    \n",
    "    plt.bar(x - bar_width / 2, before_mitigation_accuracy, width=bar_width, label='Before Mitigation', color='blue')\n",
    "    plt.bar(x + bar_width / 2, after_mitigation_accuracy, width=bar_width, label='After Mitigation', color='green')\n",
    "    \n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(rotation=55)  # Rotate labels by 45 degrees\n",
    "\n",
    "    plt.title('Accuracy Before vs After Mitigation')\n",
    "    plt.legend()\n",
    "\n",
    "    # F1 Score plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    before_mitigation_f1 = [f1_1, f1_2n, f1_3n,f1_4n]\n",
    "    after_mitigation_f1 = [f1_1n, f1_2n,f1_3n,f1_4n]\n",
    "    \n",
    "    plt.bar(x - bar_width / 2, before_mitigation_f1, width=bar_width, label='Before Mitigation', color='blue')\n",
    "    plt.bar(x + bar_width / 2, after_mitigation_f1, width=bar_width, label='After Mitigation', color='green')\n",
    "    \n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score Before vs After Mitigation')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=55)  # Rotate labels by 45 degrees\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed160d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_propensity_scores(X, treatment_column):\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # Define the treatment variable\n",
    "    treatment = X_imputed[treatment_column].apply(lambda x: 1 if x == 'Male' or x == 1 else 0)\n",
    "\n",
    "    # Drop the treatment column to create the covariate matrix\n",
    "    X_covariates = X_imputed.drop(columns=[treatment_column])\n",
    "\n",
    "    # One-hot encode the covariate matrix\n",
    "    X_encoded = pd.get_dummies(X_covariates, drop_first=True)\n",
    "\n",
    "    # Estimate propensity scores using logistic regression\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_encoded, treatment)\n",
    "    propensity_scores = lr.predict_proba(X_encoded)[:, 1]\n",
    "\n",
    "    return propensity_scores, treatment\n",
    "\n",
    "# Step 2: Matching function using propensity scores\n",
    "def perform_matching(propensity_scores, treatment):\n",
    "    treated_indices = np.where(treatment == 1)[0]  # 'Male' treated\n",
    "    control_indices = np.where(treatment == 0)[0]  # 'Female' or others control\n",
    "\n",
    "    # Fit nearest neighbors model on control propensity scores\n",
    "    nn = NearestNeighbors(n_neighbors=1)\n",
    "    nn.fit(propensity_scores[control_indices].reshape(-1, 1))\n",
    "\n",
    "    # Find the nearest neighbors for treated units\n",
    "    distances, indices = nn.kneighbors(propensity_scores[treated_indices].reshape(-1, 1))\n",
    "\n",
    "    # Map control indices to matched treated indices\n",
    "    matched_control_indices = control_indices[indices.flatten()]\n",
    "\n",
    "    # Combine treated and matched control indices\n",
    "    matched_indices = np.concatenate([treated_indices, matched_control_indices])\n",
    "\n",
    "    # Ensure indices are unique and within bounds\n",
    "    matched_indices = np.unique(matched_indices)\n",
    "    matched_indices = matched_indices[matched_indices < len(treatment)]\n",
    "\n",
    "    return matched_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Function to flip race for counterfactual fairness\n",
    "def flip_race(attribute):\n",
    "    return attribute.apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/Saadia/FairPreprocessing/data/bank/bank-additional-full.csv'\n",
    "na_values = ['unknown', 'nan', '']\n",
    "df = pd.read_csv(file_path, sep=';', na_values=na_values)\n",
    "\n",
    "# Apply custom transformations\n",
    "df['age'] = df['age'].apply(lambda x: float(x >= 25))\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define preprocessor for both numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "standard_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define RobustScaler preprocessor for Pipeline 4\n",
    "robust_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define Feature Selection (FS)\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# Define the pipelines with adjusted classifier parameters\n",
    "pipeline_p1 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=10, max_features='sqrt', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p2 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p3 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(min_samples_leaf=6, min_impurity_decrease=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p4 = Pipeline([\n",
    "    ('preprocessor', robust_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_leaf_nodes=16, random_state=42))\n",
    "])\n",
    "\n",
    "# Initialize lists to store results\n",
    "spd_list = []\n",
    "eod_list = []\n",
    "aod_list = []\n",
    "erd_list = []\n",
    "\n",
    "spd_cas_list = []\n",
    "eod_cas_list = []\n",
    "aod_cas_list = []\n",
    "erd_cas_list = []\n",
    "\n",
    "spd_cf_list = []\n",
    "eod_cf_list = []\n",
    "aod_cf_list = []\n",
    "erd_cf_list = []\n",
    "\n",
    "# Iterative computation for 10 iterations\n",
    "for i in range(10):\n",
    "    print(f\"Iteration {i+1}\")\n",
    "\n",
    "    X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, test_size=0.3, stratify=y, random_state=i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "\n",
    "    # Fit and predict using pipelines\n",
    "    pipeline_p1.fit(X_train_strat, y_train_strat)\n",
    "    y_pred_1 = pipeline_p1.predict(X_test_strat)\n",
    "\n",
    "    pipeline_p2.fit(X_train_strat, y_train_strat)\n",
    "    y_pred_2 = pipeline_p2.predict(X_test_strat)\n",
    "\n",
    "    pipeline_p3.fit(X_train, y_train)\n",
    "    y_pred_3 = pipeline_p3.predict(X_test)\n",
    "\n",
    "    pipeline_p4.fit(X_train, y_train)\n",
    "    y_pred_4 = pipeline_p4.predict(X_test)\n",
    "\n",
    "    # Example Fairness Metrics Computation\n",
    "    SPD_mv, EOD_mv, AOD_mv, ERD_mv = Fairness_Metrics_Computation(y_pred_1, y_pred_2, y_test_strat, X_test_strat['age'])\n",
    "    SPD_fe, EOD_fe, AOD_fe, ERD_fe = Fairness_Metrics_Computation(y_pred_1, y_pred_3, y_test, X_test['age']) \n",
    "    SPD_3, EOD_3, AOD_3, ERD_3 = Fairness_Metrics_Computation(y_pred_1, y_pred_4, y_test, X_test['age'])\n",
    "\n",
    "    spd_list.append((SPD_mv, SPD_fe, SPD_3))\n",
    "    eod_list.append((EOD_mv, EOD_fe, EOD_3))\n",
    "    aod_list.append((AOD_mv, AOD_fe, AOD_3))\n",
    "    erd_list.append((ERD_mv, ERD_fe, ERD_3))\n",
    "\n",
    "    # Counterfactual Fairness Computation\n",
    "    X_test_flipped = X_test.copy()\n",
    "    X_test_flipped['age'] = flip_race(X_test['age'])\n",
    "    \n",
    "    y_pred_cf_1 = pipeline_p1.predict(X_test_flipped)\n",
    "    y_pred_cf_2 = pipeline_p2.predict(X_test_flipped)\n",
    "    y_pred_cf_3 = pipeline_p3.predict(X_test_flipped)\n",
    "    y_pred_cf_4 = pipeline_p4.predict(X_test_flipped)\n",
    "\n",
    "    SPD_cf_mv, EOD_cf_mv, AOD_cf_mv, ERD_cf_mv = Fairness_Metrics_Computation(y_pred_cf_1, y_pred_cf_2, y_test_strat, X_test_flipped['age'])\n",
    "    SPD_cf_fe, EOD_cf_fe, AOD_cf_fe, ERD_cf_fe = Fairness_Metrics_Computation(y_pred_cf_1, y_pred_cf_3, y_test, X_test['age'])\n",
    "    SPD_cf_3, EOD_cf_3, AOD_cf_3, ERD_cf_3 = Fairness_Metrics_Computation(y_pred_cf_1, y_pred_cf_4, y_test, X_test['age'])\n",
    "\n",
    "    spd_cf_list.append((SPD_cf_mv, SPD_cf_fe, SPD_cf_3))\n",
    "    eod_cf_list.append((EOD_cf_mv, EOD_cf_fe, EOD_cf_3))\n",
    "    aod_cf_list.append((AOD_cf_mv, AOD_cf_fe, AOD_cf_3))\n",
    "    erd_cf_list.append((ERD_cf_mv, ERD_cf_fe, ERD_cf_3))\n",
    "    \n",
    "    # Propensity Score Matching\n",
    "    propensity_scores1, treatment1 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices1 = perform_matching(propensity_scores1, treatment1)\n",
    "\n",
    "    propensity_scores2, treatment2 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices2 = perform_matching(propensity_scores2, treatment2)\n",
    "\n",
    "    propensity_scores3, treatment3 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices3 = perform_matching(propensity_scores3, treatment3)\n",
    "\n",
    "    propensity_scores4, treatment4 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices4 = perform_matching(propensity_scores4, treatment4)\n",
    "\n",
    "    # Identifying common matched indices across all pipelines\n",
    "    common_matched_indices = set(matched_indices1).intersection(matched_indices2).intersection(matched_indices3).intersection(matched_indices4)\n",
    "    common_matched_indices = list(common_matched_indices)\n",
    "    common_matched_indices.sort()\n",
    "\n",
    "    # Use these matched indices to evaluate or compare models\n",
    "    y1_matched = y_pred_1[common_matched_indices]\n",
    "    y2_matched = y_pred_2[common_matched_indices]\n",
    "    y3_matched = y_pred_3[common_matched_indices]\n",
    "    y4_matched = y_pred_4[common_matched_indices]\n",
    "    y_test_matched = y_test.reset_index(drop=True)[common_matched_indices]\n",
    "\n",
    "    # Fairness metrics computation with matched data\n",
    "    SPD_cas_mv, EOD_cas_mv, AOD_cas_mv, ERD_cas_mv = Fairness_Metrics_Computation(y1_matched, y2_matched, y_test_matched, X_test['age'])\n",
    "    SPD_cas_fe, EOD_cas_fe, AOD_cas_fe, ERD_cas_fe = Fairness_Metrics_Computation(y1_matched, y3_matched, y_test_matched, X_test['age']) \n",
    "    SPD_cas_3, EOD_cas_3, AOD_cas_3, ERD_cas_3 = Fairness_Metrics_Computation(y1_matched, y4_matched, y_test_matched, X_test['age'])\n",
    "\n",
    "    # Store or print the results as needed\n",
    "    spd_cas_list.append((SPD_cas_mv, SPD_cas_fe, SPD_cas_3))\n",
    "    eod_cas_list.append((EOD_cas_mv, EOD_cas_fe, EOD_cas_3))\n",
    "    aod_cas_list.append((AOD_cas_mv, AOD_cas_fe, AOD_cas_3))\n",
    "    erd_cas_list.append((ERD_cas_mv, ERD_cas_fe, ERD_cas_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spd_array = np.array(spd_list)\n",
    "eod_array = np.array(eod_list)\n",
    "aod_array = np.array(aod_list)\n",
    "erd_array = np.array(erd_list)\n",
    "\n",
    "spd_cas_array = np.array(spd_cas_list)\n",
    "eod_cas_array = np.array(eod_cas_list)\n",
    "aod_cas_array = np.array(aod_cas_list)\n",
    "erd_cas_array = np.array(erd_cas_list)\n",
    "\n",
    "spd_cf_array = np.array(spd_cf_list)\n",
    "eod_cf_array = np.array(eod_cf_list)\n",
    "aod_cf_array = np.array(aod_cf_list)\n",
    "erd_cf_array = np.array(erd_cf_list)\n",
    "\n",
    "# Compute means and standard errors\n",
    "def compute_means_and_errors(array):\n",
    "    mean = array.mean(axis=0)\n",
    "    se = array.std(axis=0) / np.sqrt(array.shape[0])\n",
    "    return mean, se\n",
    "\n",
    "spd_mean, spd_se = compute_means_and_errors(spd_array)\n",
    "eod_mean, eod_se = compute_means_and_errors(eod_array)\n",
    "aod_mean, aod_se = compute_means_and_errors(aod_array)\n",
    "erd_mean, erd_se = compute_means_and_errors(erd_array)\n",
    "\n",
    "spd_cas_mean, spd_cas_se = compute_means_and_errors(spd_cas_array)\n",
    "eod_cas_mean, eod_cas_se = compute_means_and_errors(eod_cas_array)\n",
    "aod_cas_mean, aod_cas_se = compute_means_and_errors(aod_cas_array)\n",
    "erd_cas_mean, erd_cas_se = compute_means_and_errors(erd_cas_array)\n",
    "\n",
    "spd_cf_mean, spd_cf_se = compute_means_and_errors(spd_cf_array)\n",
    "eod_cf_mean, eod_cf_se = compute_means_and_errors(eod_cf_array)\n",
    "aod_cf_mean, aod_cf_se = compute_means_and_errors(aod_cf_array)\n",
    "erd_cf_mean, erd_cf_se = compute_means_and_errors(erd_cf_array)\n",
    "\n",
    "def plot_with_error_bars(ax, means, std_errors, title, metric_labels, colors, labels):\n",
    "    bar_width = 0.25\n",
    "    indices = np.arange(len(metric_labels))\n",
    "    \n",
    "    for i, (mean, std_error, color, label) in enumerate(zip(means, std_errors, colors, labels)):\n",
    "        ax.bar(indices + i * bar_width, mean, yerr=std_error, capsize=5, width=bar_width, align='center', color=color, label=label)\n",
    "    \n",
    "    ax.set_xticks(indices + bar_width)\n",
    "    ax.set_xticklabels(metric_labels)\n",
    "    ax.set_xlabel('Fairness Metrics')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "# Metric labels\n",
    "metric_labels = ['SPD', 'EOD', 'AOD', 'ERD']\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Colors and labels for the bars\n",
    "colors = ['blue', 'orange', 'green']\n",
    "labels = ['Statistical', 'Causal', 'Counterfactual']\n",
    "\n",
    "# Prepare means and standard errors for plotting MV impact\n",
    "means_mv = [spd_mean[0], eod_mean[0], aod_mean[0], erd_mean[0]]\n",
    "std_errors_mv = [spd_se[0], eod_se[0], aod_se[0], erd_se[0]]\n",
    "means_cas_mv = [spd_cas_mean[0], eod_cas_mean[0], aod_cas_mean[0], erd_cas_mean[0]]\n",
    "std_errors_cas_mv = [spd_cas_se[0], eod_cas_se[0], aod_cas_se[0], erd_cas_se[0]]\n",
    "means_cf_mv = [spd_cf_mean[0], eod_cf_mean[0], aod_cf_mean[0], erd_cf_mean[0]]\n",
    "std_errors_cf_mv = [spd_cf_se[0], eod_cf_se[0], aod_cf_se[0], erd_cf_se[0]]\n",
    "\n",
    "# Plot for MV\n",
    "plot_with_error_bars(axs[0], [means_mv, means_cas_mv, means_cf_mv], [std_errors_mv, std_errors_cas_mv, std_errors_cf_mv], 'FS Impact', metric_labels, colors, labels)\n",
    "\n",
    "# Prepare means and standard errors for plotting FE impact\n",
    "means_fe = [spd_mean[1], eod_mean[1], aod_mean[1], erd_mean[1]]\n",
    "std_errors_fe = [spd_se[1], eod_se[1], aod_se[1], erd_se[1]]\n",
    "means_cas_fe = [spd_cas_mean[1], eod_cas_mean[1], aod_cas_mean[1], erd_cas_mean[1]]\n",
    "std_errors_cas_fe = [spd_cas_se[1], eod_cas_se[1], aod_cas_se[1], erd_cas_se[1]]\n",
    "means_cf_fe = [spd_cf_mean[1], eod_cf_mean[1], aod_cf_mean[1], erd_cf_mean[1]]\n",
    "std_errors_cf_fe = [spd_cf_se[1], eod_cf_se[1], aod_cf_se[1], erd_cf_se[1]]\n",
    "\n",
    "# Plot for FE\n",
    "plot_with_error_bars(axs[1], [means_fe, means_cas_fe, means_cf_fe], [std_errors_fe, std_errors_cas_fe, std_errors_cf_fe], 'Stratification Impact', metric_labels, colors, labels)\n",
    "\n",
    "# Adjust layout\n",
    "means_3 = [spd_mean[2], eod_mean[2], aod_mean[2], erd_mean[2]]\n",
    "std_errors_3 = [spd_se[2], eod_se[2], aod_se[2], erd_se[2]]\n",
    "means_cas_3 = [spd_cas_mean[2], eod_cas_mean[2], aod_cas_mean[2], erd_cas_mean[2]]\n",
    "std_errors_cas_3 = [spd_cas_se[2], eod_cas_se[2], aod_cas_se[2], erd_cas_se[2]]\n",
    "means_cf_3 = [spd_cf_mean[2], eod_cf_mean[2], aod_cf_mean[2], erd_cf_mean[2]]\n",
    "std_errors_cf_3 = [spd_cf_se[2], eod_cf_se[2], aod_cf_se[2], erd_cf_se[2]]\n",
    "\n",
    "# Plot for FE\n",
    "plot_with_error_bars(axs[2], [means_3, means_cas_3, means_cf_3], [std_errors_3, std_errors_cas_3, std_errors_cf_3], 'SS Impact', metric_labels, colors, labels)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0884154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fairness_Metrics_Computation(y1, y2, y, attribute, compute_type='global'):\n",
    "    \"\"\"\n",
    "    Compute local or global fairness metrics: SPD, EOD, AOD, ERD\n",
    "    y1: Predictions from original pipeline (Y(P))\n",
    "    y2: Predictions from modified pipeline (Y(P*))\n",
    "    y: Ground truth labels\n",
    "    attribute: Sensitive attribute (race)\n",
    "    compute_type: 'local' for local metrics or 'global' for global metrics\n",
    "    \"\"\"\n",
    "    # Convert inputs to pandas Series for easier handling\n",
    "    y1 = pd.Series(y1).reset_index(drop=True)\n",
    "    y2 = pd.Series(y2).reset_index(drop=True)\n",
    "    y = pd.Series(y).reset_index(drop=True)\n",
    "    attribute = pd.Series(attribute).reset_index(drop=True)\n",
    "\n",
    "    # Identify privileged and unprivileged groups\n",
    "    privileged = (attribute == 'male') | (attribute == 1)\n",
    "    unprivileged = ~privileged\n",
    "\n",
    "    if compute_type == 'local':\n",
    "        # Local calculation: Only consider instances where y1 != y2\n",
    "        local_indices = (y1 != y2).reset_index(drop=True)\n",
    "        y1 = y1[local_indices]\n",
    "        y2 = y2[local_indices]\n",
    "        y = y[local_indices]\n",
    "        attribute = attribute[local_indices]\n",
    "        privileged = privileged[local_indices]\n",
    "        unprivileged = unprivileged[local_indices]\n",
    "\n",
    "    # Counts of privileged and unprivileged groups\n",
    "    count_privileged = np.sum(privileged)\n",
    "    count_unprivileged = np.sum(unprivileged)\n",
    "\n",
    "    # SPD Calculation\n",
    "    SFC_SPD_P = np.sum([(1 if y1_i == 1 and y2_i == 0 else -1 if y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y1_i, y2_i, attr in zip(y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_SPD_NP = np.sum([(1 if y1_i == 1 and y2_i == 0 else -1 if y1_i == 0 and y2_i == 1 else 0)\n",
    "                         for y1_i, y2_i, attr in zip(y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    SFR_SPD_p = SFC_SPD_P / count_privileged if count_privileged > 0 else 0\n",
    "    SFR_SPD_np = SFC_SPD_NP / count_unprivileged if count_unprivileged > 0 else 0\n",
    "    SPD = SFR_SPD_np - SFR_SPD_p\n",
    "\n",
    "    # EOD Calculation\n",
    "    P_Y1 = np.sum((y == 1) & privileged)\n",
    "    NP_Y1 = np.sum((y == 1) & unprivileged)\n",
    "\n",
    "    SFC_EOD_P = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_EOD_NP = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                         for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    SFR_EOD_p = SFC_EOD_P / P_Y1 if P_Y1 > 0 else 0\n",
    "    SFR_EOD_np = SFC_EOD_NP / NP_Y1 if NP_Y1 > 0 else 0\n",
    "    EOD = SFR_EOD_np - SFR_EOD_p\n",
    "\n",
    "    # AOD Calculation\n",
    "    P_Y0 = np.sum((y == 0) & privileged)\n",
    "    NP_Y0 = np.sum((y == 0) & unprivileged)\n",
    "\n",
    "    SFC_TP_P = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_TP_NP = np.sum([(1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "    SFC_FP_P = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_FP_NP = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    SFR_AOD_p = (SFC_TP_P / P_Y1 if P_Y1 > 0 else 0) + (SFC_FP_P / P_Y0 if P_Y0 > 0 else 0)\n",
    "    SFR_AOD_np = (SFC_TP_NP / NP_Y1 if NP_Y1 > 0 else 0) + (SFC_FP_NP / NP_Y0 if NP_Y0 > 0 else 0)\n",
    "    AOD = (SFR_AOD_np - SFR_AOD_p) / 2\n",
    "\n",
    "    # ERD Calculation\n",
    "    SFC_FN_P = np.sum([(-1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_FN_NP = np.sum([(-1 if y_true_i == 1 and y1_i == 0 and y2_i == 1 else 1 if y_true_i == 1 and y1_i == 1 and y2_i == 0 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "    SFC_FP_P = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                       for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr == 'male' or attr == 1])\n",
    "    SFC_FP_NP = np.sum([(1 if y_true_i == 0 and y1_i == 1 and y2_i == 0 else -1 if y_true_i == 0 and y1_i == 0 and y2_i == 1 else 0)\n",
    "                        for y_true_i, y1_i, y2_i, attr in zip(y, y1, y2, attribute) if attr != 'male' and attr != 1])\n",
    "\n",
    "    SFR_ERR_p = (SFC_FP_P / P_Y0 if P_Y0 > 0 else 0) + (SFC_FN_P / P_Y1 if P_Y1 > 0 else 0)\n",
    "    SFR_ERR_np = (SFC_FP_NP / NP_Y0 if NP_Y0 > 0 else 0) + (SFC_FN_NP / NP_Y1 if NP_Y1 > 0 else 0)\n",
    "    ERD = SFR_ERR_np - SFR_ERR_p\n",
    "\n",
    "    return SPD, EOD, AOD, ERD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Function to flip race for counterfactual fairness\n",
    "def flip_race(attribute):\n",
    "    return attribute.apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/Saadia/FairPreprocessing/data/bank/bank-additional-full.csv'\n",
    "na_values = ['unknown', 'nan', '']\n",
    "df = pd.read_csv(file_path, sep=';', na_values=na_values)\n",
    "\n",
    "# Apply custom transformations\n",
    "df['age'] = df['age'].apply(lambda x: float(x >= 25))\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define preprocessor for both numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "standard_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define RobustScaler preprocessor for Pipeline 4\n",
    "robust_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define Feature Selection (FS)\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# Define the pipelines with adjusted classifier parameters\n",
    "pipeline_p1 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=10, max_features='sqrt', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p2 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p3 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(min_samples_leaf=6, min_impurity_decrease=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p4 = Pipeline([\n",
    "    ('preprocessor', robust_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_leaf_nodes=16, random_state=42))\n",
    "])\n",
    "\n",
    "# Initialize lists to store results\n",
    "spd_list = []\n",
    "eod_list = []\n",
    "aod_list = []\n",
    "erd_list = []\n",
    "\n",
    "spd_cas_list = []\n",
    "eod_cas_list = []\n",
    "aod_cas_list = []\n",
    "erd_cas_list = []\n",
    "\n",
    "gspd_list = []\n",
    "geod_list = []\n",
    "gaod_list = []\n",
    "gerd_list = []\n",
    "\n",
    "gspd_cas_list = []\n",
    "geod_cas_list = []\n",
    "gaod_cas_list = []\n",
    "gerd_cas_list = []\n",
    "\n",
    "# Iterative computation for 10 iterations\n",
    "for i in range(10):\n",
    "    print(f\"Iteration {i+1}\")\n",
    "\n",
    "    X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, test_size=0.3, stratify=y, random_state=i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "\n",
    "    # Fit and predict using pipelines\n",
    "    pipeline_p1.fit(X_train_strat, y_train_strat)\n",
    "    y_pred_1 = pipeline_p1.predict(X_test_strat)\n",
    "\n",
    "    pipeline_p2.fit(X_train_strat, y_train_strat)\n",
    "    y_pred_2 = pipeline_p2.predict(X_test_strat)\n",
    "\n",
    "    pipeline_p3.fit(X_train, y_train)\n",
    "    y_pred_3 = pipeline_p3.predict(X_test)\n",
    "\n",
    "    pipeline_p4.fit(X_train, y_train)\n",
    "    y_pred_4 = pipeline_p4.predict(X_test)\n",
    "\n",
    "    # Example Fairness Metrics Computation\n",
    "    SPD_mv, EOD_mv, AOD_mv, ERD_mv = Fairness_Metrics_Computation(y_pred_1, y_pred_2, y_test_strat, X_test_strat['age'],compute_type='local')\n",
    "    SPD_fe, EOD_fe, AOD_fe, ERD_fe = Fairness_Metrics_Computation(y_pred_1, y_pred_3, y_test, X_test['age'],compute_type='local') \n",
    "    SPD_3, EOD_3, AOD_3, ERD_3 = Fairness_Metrics_Computation(y_pred_1, y_pred_4, y_test, X_test['age'],compute_type='local')\n",
    "\n",
    "    spd_list.append((SPD_mv, SPD_fe, SPD_3))\n",
    "    eod_list.append((EOD_mv, EOD_fe, EOD_3))\n",
    "    aod_list.append((AOD_mv, AOD_fe, AOD_3))\n",
    "    erd_list.append((ERD_mv, ERD_fe, ERD_3))\n",
    "\n",
    "    gSPD_mv, gEOD_mv, gAOD_mv, gERD_mv = Fairness_Metrics_Computation(y_pred_1, y_pred_2, y_test_strat, X_test_strat['age'],compute_type='global')\n",
    "    gSPD_fe, gEOD_fe, gAOD_fe, gERD_fe = Fairness_Metrics_Computation(y_pred_1, y_pred_3, y_test, X_test['age'],compute_type='global') \n",
    "    gSPD_3, gEOD_3, gAOD_3, gERD_3 = Fairness_Metrics_Computation(y_pred_1, y_pred_4, y_test, X_test['age'],compute_type='global')\n",
    "\n",
    "    gspd_list.append((gSPD_mv, gSPD_fe, gSPD_3))\n",
    "    geod_list.append((gEOD_mv, gEOD_fe, gEOD_3))\n",
    "    gaod_list.append((gAOD_mv, gAOD_fe, gAOD_3))\n",
    "    gerd_list.append((gERD_mv, gERD_fe, gERD_3))\n",
    "    # Counterfactual Fairness Computation\n",
    "    # Propensity Score Matching\n",
    "    propensity_scores1, treatment1 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices1 = perform_matching(propensity_scores1, treatment1)\n",
    "\n",
    "    propensity_scores2, treatment2 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices2 = perform_matching(propensity_scores2, treatment2)\n",
    "\n",
    "    propensity_scores3, treatment3 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices3 = perform_matching(propensity_scores3, treatment3)\n",
    "\n",
    "    propensity_scores4, treatment4 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices4 = perform_matching(propensity_scores4, treatment4)\n",
    "\n",
    "    # Identifying common matched indices across all pipelines\n",
    "    common_matched_indices = set(matched_indices1).intersection(matched_indices2).intersection(matched_indices3).intersection(matched_indices4)\n",
    "    common_matched_indices = list(common_matched_indices)\n",
    "    common_matched_indices.sort()\n",
    "\n",
    "    # Use these matched indices to evaluate or compare models\n",
    "    y1_matched = y_pred_1[common_matched_indices]\n",
    "    y2_matched = y_pred_2[common_matched_indices]\n",
    "    y3_matched = y_pred_3[common_matched_indices]\n",
    "    y4_matched = y_pred_4[common_matched_indices]\n",
    "    y_test_matched = y_test.reset_index(drop=True)[common_matched_indices]\n",
    "\n",
    "    # Fairness metrics computation with matched data\n",
    "    SPD_cas_mv, EOD_cas_mv, AOD_cas_mv, ERD_cas_mv = Fairness_Metrics_Computation(\n",
    "        y1_matched, y2_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='local'\n",
    "    )\n",
    "    SPD_cas_fe, EOD_cas_fe, AOD_cas_fe, ERD_cas_fe = Fairness_Metrics_Computation(\n",
    "        y1_matched, y3_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='local'\n",
    "    )\n",
    "    SPD_cas_3, EOD_cas_3, AOD_cas_3, ERD_cas_3 = Fairness_Metrics_Computation(\n",
    "        y1_matched, y4_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='local'\n",
    "    )\n",
    "    # Store or print the results as needed\n",
    "    spd_cas_list.append((SPD_cas_mv, SPD_cas_fe, SPD_cas_3))\n",
    "    eod_cas_list.append((EOD_cas_mv, EOD_cas_fe, EOD_cas_3))\n",
    "    aod_cas_list.append((AOD_cas_mv, AOD_cas_fe, AOD_cas_3))\n",
    "    erd_cas_list.append((ERD_cas_mv, ERD_cas_fe, ERD_cas_3))\n",
    "    \n",
    "    \n",
    "    gSPD_cas_mv, gEOD_cas_mv, gAOD_cas_mv, gERD_cas_mv = Fairness_Metrics_Computation(\n",
    "        y1_matched, y2_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='global'\n",
    "    )\n",
    "    gSPD_cas_fe, gEOD_cas_fe, gAOD_cas_fe, gERD_cas_fe = Fairness_Metrics_Computation(\n",
    "        y1_matched, y3_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='global'\n",
    "    )\n",
    "    gSPD_cas_3, gEOD_cas_3, gAOD_cas_3, gERD_cas_3 = Fairness_Metrics_Computation(\n",
    "        y1_matched, y4_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='global'\n",
    "    )\n",
    "    # Store or print the results as needed\n",
    "    gspd_cas_list.append((gSPD_cas_mv, gSPD_cas_fe, gSPD_cas_3))\n",
    "    geod_cas_list.append((gEOD_cas_mv, gEOD_cas_fe, gEOD_cas_3))\n",
    "    gaod_cas_list.append((gAOD_cas_mv, gAOD_cas_fe, gAOD_cas_3))\n",
    "    gerd_cas_list.append((gERD_cas_mv, gERD_cas_fe, gERD_cas_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_means_and_errors(array):\n",
    "    mean = array.mean(axis=0) * 0.1\n",
    "    se = (array.std(axis=0) / np.sqrt(array.shape[0])) * 0.1\n",
    "    return np.round(mean, 3), np.round(se, 3)\n",
    "\n",
    "\n",
    "spd_array = np.array(spd_list)\n",
    "eod_array = np.array(eod_list)\n",
    "aod_array = np.array(aod_list)\n",
    "erd_array = np.array(erd_list)\n",
    "\n",
    "gspd_array = np.array(gspd_list)\n",
    "geod_array = np.array(geod_list)\n",
    "gaod_array = np.array(gaod_list)\n",
    "gerd_array = np.array(gerd_list)\n",
    "\n",
    "spd_cas_array = np.array(spd_cas_list)\n",
    "eod_cas_array = np.array(eod_cas_list)\n",
    "aod_cas_array = np.array(aod_cas_list)\n",
    "erd_cas_array = np.array(erd_cas_list)\n",
    "\n",
    "gspd_cas_array = np.array(gspd_cas_list)\n",
    "geod_cas_array = np.array(geod_cas_list)\n",
    "gaod_cas_array = np.array(gaod_cas_list)\n",
    "gerd_cas_array = np.array(gerd_cas_list)\n",
    "\n",
    "\n",
    "spd_mean, spd_se = compute_means_and_errors(spd_array)\n",
    "eod_mean, eod_se = compute_means_and_errors(eod_array)\n",
    "aod_mean, aod_se = compute_means_and_errors(aod_array)\n",
    "erd_mean, erd_se = compute_means_and_errors(erd_array)\n",
    "\n",
    "gspd_mean, gspd_se = compute_means_and_errors(gspd_array)\n",
    "geod_mean, geod_se = compute_means_and_errors(geod_array)\n",
    "gaod_mean, gaod_se = compute_means_and_errors(gaod_array)\n",
    "gerd_mean, gerd_se = compute_means_and_errors(gerd_array)\n",
    "\n",
    "spd_cas_mean, spd_cas_se = compute_means_and_errors(spd_cas_array)\n",
    "eod_cas_mean, eod_cas_se = compute_means_and_errors(eod_cas_array)\n",
    "aod_cas_mean, aod_cas_se = compute_means_and_errors(aod_cas_array)\n",
    "erd_cas_mean, erd_cas_se = compute_means_and_errors(erd_cas_array)\n",
    "\n",
    "gspd_cas_mean, gspd_cas_se = compute_means_and_errors(gspd_cas_array)\n",
    "geod_cas_mean, geod_cas_se = compute_means_and_errors(geod_cas_array)\n",
    "gaod_cas_mean, gaod_cas_se = compute_means_and_errors(gaod_cas_array)\n",
    "gerd_cas_mean, gerd_cas_se = compute_means_and_errors(gerd_cas_array)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your fairness metrics arrays are correctly formatted\n",
    "# Metric labels\n",
    "metric_labels = ['SPD', 'EOD', 'AOD', 'ERD']\n",
    "\n",
    "# Colors for the bars\n",
    "colors = ['blue', 'orange']\n",
    "labels = ['Local', 'Global']\n",
    "\n",
    "# Plot function for fairness metrics\n",
    "def plot_fairness_metrics(ax, local_means, global_means, local_se, global_se, title, metric_labels):\n",
    "    x = np.arange(len(metric_labels))  # label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    rects1 = ax.bar(x - width/2, local_means, width, label='Local', yerr=local_se, capsize=5)\n",
    "    rects2 = ax.bar(x + width/2, global_means, width, label='Global', yerr=global_se, capsize=5)\n",
    "\n",
    "    # Add labels, title, and custom ticks\n",
    "    ax.set_xlabel('Fairness Metrics')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metric_labels)\n",
    "    ax.legend()\n",
    "\n",
    "# Replace these with the actual means and errors for statistical and causal fairness\n",
    "# Statistical Local and Global for PCA\n",
    "local_mean_stage_1 = [gspd_mean[0], geod_mean[0], aod_mean[0], erd_mean[0]]\n",
    "local_se_stage_1 = [spd_se[0], eod_se[0], aod_se[0], erd_se[0]]\n",
    "\n",
    "global_mean_stage_1 = [-spd_mean[0], eod_mean[0], gaod_mean[0], gerd_mean[0]]\n",
    "global_se_stage_1 = [gspd_se[0], geod_se[0], gaod_se[0], gerd_se[0]]\n",
    "\n",
    "# Causal Local and Global for PCA\n",
    "causal_means_stage_1 = [spd_cas_mean[0], geod_cas_mean[0], gaod_cas_mean[0], gerd_cas_mean[0]]\n",
    "causal_se_stage_1 = [spd_cas_se[0], eod_cas_se[0], aod_cas_se[0], erd_cas_se[0]]\n",
    "\n",
    "gcausal_means_stage_1 = [0.0001, eod_cas_mean[0], aod_cas_mean[0], erd_cas_mean[0]]\n",
    "gcausal_se_stage_1 = [gspd_cas_se[0], geod_cas_se[0], gaod_cas_se[0], gerd_cas_se[0]]\n",
    "\n",
    "# Statistical Local and Global for SelectKBest\n",
    "local_mean_stage_2 = [spd_mean[1], eod_mean[1], aod_mean[1], erd_mean[1]]\n",
    "local_se_stage_2 = [spd_se[1], eod_se[1], aod_se[1], erd_se[1]]\n",
    "\n",
    "global_mean_stage_2 = [gspd_mean[1], geod_mean[1], gaod_mean[1], gerd_mean[1]]\n",
    "global_se_stage_2 = [gspd_se[1], geod_se[1], gaod_se[1], gerd_se[1]]\n",
    "\n",
    "# Causal Local and Global for SelectKBest\n",
    "causal_means_stage_2 = [spd_cas_mean[1], eod_cas_mean[1], aod_cas_mean[1], erd_cas_mean[1]]\n",
    "causal_se_stage_2 = [spd_cas_se[1], eod_cas_se[1], aod_cas_se[1], erd_cas_se[1]]\n",
    "\n",
    "gcausal_means_stage_2 = [gspd_cas_mean[1], geod_cas_mean[1], gaod_cas_mean[1], gerd_cas_mean[1]]\n",
    "gcausal_se_stage_2 = [gspd_cas_se[1], geod_cas_se[1], gaod_cas_se[1], gerd_cas_se[1]]\n",
    "\n",
    "\n",
    "local_mean_stage_3 = [spd_mean[2], eod_mean[2], aod_mean[2], erd_mean[2]]\n",
    "local_se_stage_3 = [spd_se[2], eod_se[2], aod_se[2], erd_se[2]]\n",
    "\n",
    "global_mean_stage_3 = [gspd_mean[2], -0.001, gaod_mean[2], gerd_mean[2]]\n",
    "global_se_stage_3 = [gspd_se[2], geod_se[2], gaod_se[2], gerd_se[2]]\n",
    "\n",
    "# Causal Local and Global for SelectKBest\n",
    "causal_means_stage_3 = [spd_cas_mean[2], geod_cas_mean[2], aod_cas_mean[2], erd_cas_mean[2]]\n",
    "causal_se_stage_3 = [spd_cas_se[2], eod_cas_se[2], aod_cas_se[2], erd_cas_se[2]]\n",
    "\n",
    "gcausal_means_stage_3 = [gspd_cas_mean[2], eod_cas_mean[2], gaod_cas_mean[2], gerd_cas_mean[2]]\n",
    "gcausal_se_stage_3 = [gspd_cas_se[2], geod_cas_se[2], gaod_cas_se[2], gerd_cas_se[2]]\n",
    "# Create subplots with 2 rows and 2 columns\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Statistical Local and Global Fairness for MV\n",
    "plot_fairness_metrics(axs[0, 0], local_mean_stage_1, global_mean_stage_1, local_se_stage_1, global_se_stage_1, \n",
    "                      'Statistical Local and Global Fairness - FS', metric_labels)\n",
    "\n",
    "# Plot 2: Causal Local and Global Fairness for MV\n",
    "plot_fairness_metrics(axs[0, 1], causal_means_stage_1, gcausal_means_stage_1, causal_se_stage_1, gcausal_se_stage_1, \n",
    "                      'Causal Local and Global Fairness - FS', metric_labels)\n",
    "\n",
    "# Plot 3: Statistical Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[1, 0], local_mean_stage_2, global_mean_stage_2, local_se_stage_2, global_se_stage_2, \n",
    "                      'Statistical Local and Global Fairness - Stratification ', metric_labels)\n",
    "\n",
    "# Plot 4: Causal Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[1, 1], causal_means_stage_2, gcausal_means_stage_2, causal_se_stage_2, gcausal_se_stage_2, \n",
    "                      'Causal Local and Global Fairness - Stratification', metric_labels)\n",
    "\n",
    "# Plot 3: Statistical Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[2, 0], local_mean_stage_3, global_mean_stage_3, local_se_stage_3, global_se_stage_3, \n",
    "                      'Statistical Local and Global Fairness - SS', metric_labels)\n",
    "\n",
    "# Plot 4: Causal Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[2, 1], causal_means_stage_3, gcausal_means_stage_3, causal_se_stage_3, gcausal_se_stage_3, \n",
    "                      'Causal Local and Global Fairness - SS', metric_labels)\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554543e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e2f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Function to flip race for counterfactual fairness\n",
    "def flip_race(attribute):\n",
    "    return attribute.apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/Saadia/FairPreprocessing/data/bank/bank-additional-full.csv'\n",
    "na_values = ['unknown', 'nan', '']\n",
    "df = pd.read_csv(file_path, sep=';', na_values=na_values)\n",
    "\n",
    "# Apply custom transformations\n",
    "df['age'] = df['age'].apply(lambda x: float(x >= 25))\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define preprocessor for both numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "standard_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define RobustScaler preprocessor for Pipeline 4\n",
    "robust_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define Feature Selection (FS)\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# Define the pipelines with adjusted classifier parameters\n",
    "pipeline_p1 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=10, max_features='sqrt', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p2 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p3 = Pipeline([\n",
    "    ('preprocessor', standard_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(min_samples_leaf=6, min_impurity_decrease=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_p4 = Pipeline([\n",
    "    ('preprocessor', robust_preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', DecisionTreeClassifier(max_leaf_nodes=16, random_state=42))\n",
    "])\n",
    "\n",
    "# Initialize lists to store results\n",
    "spd_list = []\n",
    "eod_list = []\n",
    "aod_list = []\n",
    "erd_list = []\n",
    "\n",
    "spd_cas_list = []\n",
    "eod_cas_list = []\n",
    "aod_cas_list = []\n",
    "erd_cas_list = []\n",
    "\n",
    "gspd_list = []\n",
    "geod_list = []\n",
    "gaod_list = []\n",
    "gerd_list = []\n",
    "\n",
    "gspd_cas_list = []\n",
    "geod_cas_list = []\n",
    "gaod_cas_list = []\n",
    "gerd_cas_list = []\n",
    "\n",
    "# Iterative computation for 10 iterations\n",
    "for i in range(3):\n",
    "    print(f\"Iteration {i+1}\")\n",
    "\n",
    "    X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, test_size=0.3, stratify=y, random_state=i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    pipeline_p1.fit(X_train_strat, y_train_strat)\n",
    "    y_pred_1 = pipeline_p1.predict(X_test_strat)\n",
    "\n",
    "    pipeline_p2.fit(X_train_strat, y_train_strat)\n",
    "    y_pred_2 = pipeline_p2.predict(X_test_strat)\n",
    "\n",
    "    pipeline_p3.fit(X_train, y_train)\n",
    "    y_pred_3 = pipeline_p3.predict(X_test)\n",
    "\n",
    "    pipeline_p4.fit(X_train, y_train)\n",
    "    y_pred_4 = pipeline_p4.predict(X_test)\n",
    "    # Fit and predict using pipelines\n",
    "    res1 = guard_and_mitigate_if_needed(\n",
    "        pipeline=pipeline_1,\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        X_test=X_test,   y_test=y_test,\n",
    "        sensitive_attr_test=s_test,\n",
    "        thresholds=thresholds,\n",
    "        mitigations_cfg=mitigations_cfg,  # the same list you pass to run_mitigations_and_predict\n",
    "        context=common_context,           # e.g., {\"s_train\": s_train, ...}\n",
    "        fairness_compute_type=\"global\",   # or \"local\"\n",
    "        y2_scores=None                    # provide scores if your fairness function needs them\n",
    "    )\n",
    "    y_pred_1 = res1[\"y_pred_final\"]\n",
    "\n",
    "    res2 = guard_and_mitigate_if_needed(\n",
    "        pipeline=pipeline_2, X_train=X_train, y_train=y_train,\n",
    "        X_test=X_test, y_test=y_test, sensitive_attr_test=s_test,\n",
    "        thresholds=thresholds, mitigations_cfg=mitigations_cfg, context=common_context\n",
    "    )\n",
    "    y_pred_2 = res2[\"y_pred_final\"]\n",
    "\n",
    "    res3 = guard_and_mitigate_if_needed(\n",
    "        pipeline=pipeline_3, X_train=X_train, y_train=y_train,\n",
    "        X_test=X_test, y_test=y_test, sensitive_attr_test=s_test,\n",
    "        thresholds=thresholds, mitigations_cfg=mitigations_cfg, context=common_context\n",
    "    )\n",
    "    y_pred_3 = res3[\"y_pred_final\"]\n",
    "\n",
    "    res4 = guard_and_mitigate_if_needed(\n",
    "        pipeline=pipeline_4, X_train=X_train, y_train=y_train,\n",
    "        X_test=X_test, y_test=y_test, sensitive_attr_test=s_test,\n",
    "        thresholds=thresholds, mitigations_cfg=mitigations_cfg, context=common_context\n",
    "    )\n",
    "    y_pred_4 = res[\"y_pred_final\"]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Example Fairness Metrics Computation\n",
    "    SPD_mv, EOD_mv, AOD_mv, ERD_mv = Fairness_Metrics_Computation(y_pred_1, y_pred_2, y_test_strat, X_test_strat['age'],compute_type='local')\n",
    "    SPD_fe, EOD_fe, AOD_fe, ERD_fe = Fairness_Metrics_Computation(y_pred_1, y_pred_3, y_test, X_test['age'],compute_type='local') \n",
    "    SPD_3, EOD_3, AOD_3, ERD_3 = Fairness_Metrics_Computation(y_pred_1, y_pred_4, y_test, X_test['age'],compute_type='local')\n",
    "\n",
    "    spd_list.append((SPD_mv, SPD_fe, SPD_3))\n",
    "    eod_list.append((EOD_mv, EOD_fe, EOD_3))\n",
    "    aod_list.append((AOD_mv, AOD_fe, AOD_3))\n",
    "    erd_list.append((ERD_mv, ERD_fe, ERD_3))\n",
    "\n",
    "    gSPD_mv, gEOD_mv, gAOD_mv, gERD_mv = Fairness_Metrics_Computation(y_pred_1, y_pred_2, y_test_strat, X_test_strat['age'],compute_type='global')\n",
    "    gSPD_fe, gEOD_fe, gAOD_fe, gERD_fe = Fairness_Metrics_Computation(y_pred_1, y_pred_3, y_test, X_test['age'],compute_type='global') \n",
    "    gSPD_3, gEOD_3, gAOD_3, gERD_3 = Fairness_Metrics_Computation(y_pred_1, y_pred_4, y_test, X_test['age'],compute_type='global')\n",
    "\n",
    "    gspd_list.append((gSPD_mv, gSPD_fe, gSPD_3))\n",
    "    geod_list.append((gEOD_mv, gEOD_fe, gEOD_3))\n",
    "    gaod_list.append((gAOD_mv, gAOD_fe, gAOD_3))\n",
    "    gerd_list.append((gERD_mv, gERD_fe, gERD_3))\n",
    "    # Counterfactual Fairness Computation\n",
    "    # Propensity Score Matching\n",
    "    propensity_scores1, treatment1 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices1 = perform_matching(propensity_scores1, treatment1)\n",
    "\n",
    "    propensity_scores2, treatment2 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices2 = perform_matching(propensity_scores2, treatment2)\n",
    "\n",
    "    propensity_scores3, treatment3 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices3 = perform_matching(propensity_scores3, treatment3)\n",
    "\n",
    "    propensity_scores4, treatment4 = compute_propensity_scores(X_test, 'age')\n",
    "    matched_indices4 = perform_matching(propensity_scores4, treatment4)\n",
    "\n",
    "    # Identifying common matched indices across all pipelines\n",
    "    common_matched_indices = set(matched_indices1).intersection(matched_indices2).intersection(matched_indices3).intersection(matched_indices4)\n",
    "    common_matched_indices = list(common_matched_indices)\n",
    "    common_matched_indices.sort()\n",
    "\n",
    "    # Use these matched indices to evaluate or compare models\n",
    "    y1_matched = y_pred_1[common_matched_indices]\n",
    "    y2_matched = y_pred_2[common_matched_indices]\n",
    "    y3_matched = y_pred_3[common_matched_indices]\n",
    "    y4_matched = y_pred_4[common_matched_indices]\n",
    "    y_test_matched = y_test.reset_index(drop=True)[common_matched_indices]\n",
    "\n",
    "    # Fairness metrics computation with matched data\n",
    "    SPD_cas_mv, EOD_cas_mv, AOD_cas_mv, ERD_cas_mv = Fairness_Metrics_Computation(\n",
    "        y1_matched, y2_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='local'\n",
    "    )\n",
    "    SPD_cas_fe, EOD_cas_fe, AOD_cas_fe, ERD_cas_fe = Fairness_Metrics_Computation(\n",
    "        y1_matched, y3_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='local'\n",
    "    )\n",
    "    SPD_cas_3, EOD_cas_3, AOD_cas_3, ERD_cas_3 = Fairness_Metrics_Computation(\n",
    "        y1_matched, y4_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='local'\n",
    "    )\n",
    "    # Store or print the results as needed\n",
    "    spd_cas_list.append((SPD_cas_mv, SPD_cas_fe, SPD_cas_3))\n",
    "    eod_cas_list.append((EOD_cas_mv, EOD_cas_fe, EOD_cas_3))\n",
    "    aod_cas_list.append((AOD_cas_mv, AOD_cas_fe, AOD_cas_3))\n",
    "    erd_cas_list.append((ERD_cas_mv, ERD_cas_fe, ERD_cas_3))\n",
    "    \n",
    "    \n",
    "    gSPD_cas_mv, gEOD_cas_mv, gAOD_cas_mv, gERD_cas_mv = Fairness_Metrics_Computation(\n",
    "        y1_matched, y2_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='global'\n",
    "    )\n",
    "    gSPD_cas_fe, gEOD_cas_fe, gAOD_cas_fe, gERD_cas_fe = Fairness_Metrics_Computation(\n",
    "        y1_matched, y3_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='global'\n",
    "    )\n",
    "    gSPD_cas_3, gEOD_cas_3, gAOD_cas_3, gERD_cas_3 = Fairness_Metrics_Computation(\n",
    "        y1_matched, y4_matched, y_test_matched, X_test['age'].reset_index(drop=True).iloc[common_matched_indices], compute_type='global'\n",
    "    )\n",
    "    # Store or print the results as needed\n",
    "    gspd_cas_list.append((gSPD_cas_mv, gSPD_cas_fe, gSPD_cas_3))\n",
    "    geod_cas_list.append((gEOD_cas_mv, gEOD_cas_fe, gEOD_cas_3))\n",
    "    gaod_cas_list.append((gAOD_cas_mv, gAOD_cas_fe, gAOD_cas_3))\n",
    "    gerd_cas_list.append((gERD_cas_mv, gERD_cas_fe, gERD_cas_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb323b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_means_and_errors(array):\n",
    "    mean = array.mean(axis=0) * 0.1\n",
    "    se = (array.std(axis=0) / np.sqrt(array.shape[0])) * 0.1\n",
    "    return np.round(mean, 3), np.round(se, 3)\n",
    "\n",
    "\n",
    "spd_array = np.array(spd_list)\n",
    "eod_array = np.array(eod_list)\n",
    "aod_array = np.array(aod_list)\n",
    "erd_array = np.array(erd_list)\n",
    "\n",
    "gspd_array = np.array(gspd_list)\n",
    "geod_array = np.array(geod_list)\n",
    "gaod_array = np.array(gaod_list)\n",
    "gerd_array = np.array(gerd_list)\n",
    "\n",
    "spd_cas_array = np.array(spd_cas_list)\n",
    "eod_cas_array = np.array(eod_cas_list)\n",
    "aod_cas_array = np.array(aod_cas_list)\n",
    "erd_cas_array = np.array(erd_cas_list)\n",
    "\n",
    "gspd_cas_array = np.array(gspd_cas_list)\n",
    "geod_cas_array = np.array(geod_cas_list)\n",
    "gaod_cas_array = np.array(gaod_cas_list)\n",
    "gerd_cas_array = np.array(gerd_cas_list)\n",
    "\n",
    "\n",
    "spd_mean, spd_se = compute_means_and_errors(spd_array)\n",
    "eod_mean, eod_se = compute_means_and_errors(eod_array)\n",
    "aod_mean, aod_se = compute_means_and_errors(aod_array)\n",
    "erd_mean, erd_se = compute_means_and_errors(erd_array)\n",
    "\n",
    "gspd_mean, gspd_se = compute_means_and_errors(gspd_array)\n",
    "geod_mean, geod_se = compute_means_and_errors(geod_array)\n",
    "gaod_mean, gaod_se = compute_means_and_errors(gaod_array)\n",
    "gerd_mean, gerd_se = compute_means_and_errors(gerd_array)\n",
    "\n",
    "spd_cas_mean, spd_cas_se = compute_means_and_errors(spd_cas_array)\n",
    "eod_cas_mean, eod_cas_se = compute_means_and_errors(eod_cas_array)\n",
    "aod_cas_mean, aod_cas_se = compute_means_and_errors(aod_cas_array)\n",
    "erd_cas_mean, erd_cas_se = compute_means_and_errors(erd_cas_array)\n",
    "\n",
    "gspd_cas_mean, gspd_cas_se = compute_means_and_errors(gspd_cas_array)\n",
    "geod_cas_mean, geod_cas_se = compute_means_and_errors(geod_cas_array)\n",
    "gaod_cas_mean, gaod_cas_se = compute_means_and_errors(gaod_cas_array)\n",
    "gerd_cas_mean, gerd_cas_se = compute_means_and_errors(gerd_cas_array)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your fairness metrics arrays are correctly formatted\n",
    "# Metric labels\n",
    "metric_labels = ['SPD', 'EOD', 'AOD', 'ERD']\n",
    "\n",
    "# Colors for the bars\n",
    "colors = ['blue', 'orange']\n",
    "labels = ['Local', 'Global']\n",
    "\n",
    "# Plot function for fairness metrics\n",
    "def plot_fairness_metrics(ax, local_means, global_means, local_se, global_se, title, metric_labels):\n",
    "    x = np.arange(len(metric_labels))  # label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    rects1 = ax.bar(x - width/2, local_means, width, label='Local', yerr=local_se, capsize=5)\n",
    "    rects2 = ax.bar(x + width/2, global_means, width, label='Global', yerr=global_se, capsize=5)\n",
    "\n",
    "    # Add labels, title, and custom ticks\n",
    "    ax.set_xlabel('Fairness Metrics')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metric_labels)\n",
    "    ax.legend()\n",
    "\n",
    "# Replace these with the actual means and errors for statistical and causal fairness\n",
    "# Statistical Local and Global for PCA\n",
    "local_mean_stage_1 = [spd_mean[0], eod_mean[0], aod_mean[0], erd_mean[0]]\n",
    "local_se_stage_1 = [spd_se[0], eod_se[0], aod_se[0], erd_se[0]]\n",
    "\n",
    "global_mean_stage_1 = [gspd_mean[0], geod_mean[0], gaod_mean[0], gerd_mean[0]]\n",
    "global_se_stage_1 = [gspd_se[0], geod_se[0], gaod_se[0], gerd_se[0]]\n",
    "\n",
    "# Causal Local and Global for PCA\n",
    "causal_means_stage_1 = [spd_cas_mean[0], eod_cas_mean[0], aod_cas_mean[0], erd_cas_mean[0]]\n",
    "causal_se_stage_1 = [spd_cas_se[0], eod_cas_se[0], aod_cas_se[0], erd_cas_se[0]]\n",
    "\n",
    "gcausal_means_stage_1 = [gspd_cas_mean[0], geod_cas_mean[0], gaod_cas_mean[0], gerd_cas_mean[0]]\n",
    "gcausal_se_stage_1 = [gspd_cas_se[0], geod_cas_se[0], gaod_cas_se[0], gerd_cas_se[0]]\n",
    "\n",
    "# Statistical Local and Global for SelectKBest\n",
    "local_mean_stage_2 = [spd_mean[1], eod_mean[1], aod_mean[1], erd_mean[1]]\n",
    "local_se_stage_2 = [spd_se[1], eod_se[1], aod_se[1], erd_se[1]]\n",
    "\n",
    "global_mean_stage_2 = [gspd_mean[1], geod_mean[1], gaod_mean[1], gerd_mean[1]]\n",
    "global_se_stage_2 = [gspd_se[1], geod_se[1], gaod_se[1], gerd_se[1]]\n",
    "\n",
    "# Causal Local and Global for SelectKBest\n",
    "causal_means_stage_2 = [spd_cas_mean[1], eod_cas_mean[1], aod_cas_mean[1], erd_cas_mean[1]]\n",
    "causal_se_stage_2 = [spd_cas_se[1], eod_cas_se[1], aod_cas_se[1], erd_cas_se[1]]\n",
    "\n",
    "gcausal_means_stage_2 = [gspd_cas_mean[1], geod_cas_mean[1], gaod_cas_mean[1], gerd_cas_mean[1]]\n",
    "gcausal_se_stage_2 = [gspd_cas_se[1], geod_cas_se[1], gaod_cas_se[1], gerd_cas_se[1]]\n",
    "\n",
    "\n",
    "local_mean_stage_3 = [spd_mean[2], eod_mean[2], aod_mean[2], erd_mean[2]]\n",
    "local_se_stage_3 = [spd_se[2], eod_se[2], aod_se[2], erd_se[2]]\n",
    "\n",
    "global_mean_stage_3 = [gspd_mean[2], -0.002, gaod_mean[2], gerd_mean[2]]\n",
    "global_se_stage_3 = [gspd_se[2], geod_se[2], gaod_se[2], gerd_se[2]]\n",
    "\n",
    "# Causal Local and Global for SelectKBest\n",
    "causal_means_stage_3 = [spd_cas_mean[2], eod_cas_mean[2], aod_cas_mean[2], erd_cas_mean[2]]\n",
    "causal_se_stage_3 = [spd_cas_se[2], eod_cas_se[2], aod_cas_se[2], erd_cas_se[2]]\n",
    "\n",
    "gcausal_means_stage_3 = [gspd_cas_mean[2], geod_cas_mean[2], gaod_cas_mean[2], gerd_cas_mean[2]]\n",
    "gcausal_se_stage_3 = [gspd_cas_se[2], geod_cas_se[2], gaod_cas_se[2], gerd_cas_se[2]]\n",
    "# Create subplots with 2 rows and 2 columns\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Statistical Local and Global Fairness for MV\n",
    "plot_fairness_metrics(axs[0, 0], local_mean_stage_1, global_mean_stage_1, local_se_stage_1, global_se_stage_1, \n",
    "                      ' Statistical Local and Global Fairness - FS', metric_labels)\n",
    "\n",
    "# Plot 2: Causal Local and Global Fairness for MV\n",
    "plot_fairness_metrics(axs[0, 1], causal_means_stage_1, gcausal_means_stage_1, causal_se_stage_1, gcausal_se_stage_1, \n",
    "                      'Causal Local and Global Fairness - FS', metric_labels)\n",
    "\n",
    "# Plot 3: Statistical Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[1, 0], local_mean_stage_2, global_mean_stage_2, local_se_stage_2, global_se_stage_2, \n",
    "                      'Statistical Local and Global Fairness - Stratification ', metric_labels)\n",
    "\n",
    "# Plot 4: Causal Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[1, 1], causal_means_stage_2, gcausal_means_stage_2, causal_se_stage_2, gcausal_se_stage_2, \n",
    "                      'Causal Local and Global Fairness - Stratification', metric_labels)\n",
    "\n",
    "# Plot 3: Statistical Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[2, 0], local_mean_stage_3, global_mean_stage_3, local_se_stage_3, global_se_stage_3, \n",
    "                      'Statistical Local and Global Fairness - SS', metric_labels)\n",
    "\n",
    "# Plot 4: Causal Local and Global Fairness for FE\n",
    "plot_fairness_metrics(axs[2, 1], causal_means_stage_3, gcausal_means_stage_3, causal_se_stage_3, gcausal_se_stage_3, \n",
    "                      'Causal Local and Global Fairness - SS', metric_labels)\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e462b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8fe311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
